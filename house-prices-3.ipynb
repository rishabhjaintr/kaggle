{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.ensemble import AdaBoostRegressor, GradientBoostingRegressor, RandomForestRegressor, StackingRegressor\n",
    "from sklearn.linear_model import ElasticNet, Lasso, Ridge, LinearRegression\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import mean_squared_log_error, make_scorer\n",
    "from sklearn.model_selection import GridSearchCV, ShuffleSplit, KFold, cross_validate\n",
    "from sklearn.preprocessing import FunctionTransformer, OneHotEncoder, OrdinalEncoder, QuantileTransformer, MinMaxScaler, StandardScaler, PowerTransformer, RobustScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import FeatureUnion, Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from scipy import stats\n",
    "\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgbm\n",
    "import pygam as gam\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "import re, itertools, functools, os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load training dataset\n",
    "train_df = pd.read_csv('train.csv')\n",
    "# load submission dataset\n",
    "submission_df = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW4AAAERCAYAAABb1k2bAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy86wFpkAAAACXBIWXMAAAsTAAALEwEAmpwYAAApuklEQVR4nO3deXxcZ33v8c9vFo32zVpsyZYdr0nsxI7tJHZCEieEkEAI3F64Zb1AoW6BUqALhQsty73tvW3ae6EFCmYvkKUJAUpYkhQISSA4sR3HsRPvizZrsbVrtI6e+8eMbNnRMrJn5sxovu/XSy+PRjNnvh7LXx095znPMeccIiKSOXxeBxARkdlRcYuIZBgVt4hIhlFxi4hkGBW3iEiGUXGLiGSYpBW3mX3DzNrMbG+CtldnZo+a2Utm9qKZLUnEdkVEMk0y97i/BdyewO39G3C3c+4y4BqgLYHbFhHJGEkrbufcE0DHxPvMbJmZ/dzMdprZk2Z2aTzbMrPLgYBz7rHYtvucc+HEpxYRSX+pHuPeBnzQObcB+AvgS3E+byXQZWYPmdlzZna3mfmTllJEJI0FUvVCZlYIXAc8YGbjd4diX/s94LOTPK3JOfdqojlvAK4C6oH7gXcBX09uahGR9JOy4ia6d9/lnFt3/heccw8BD03z3EbgOefcUQAz+yGwCRW3iGShlA2VOOd6gGNm9iYAi1ob59OfBcrMrDL2+S3Ai0mIKSKS9pI5HfBe4GlglZk1mtl7gLcB7zGz54F9wOvj2ZZzLkJ0TPwXZvYCYMBXk5NcRCS9mZZ1FRHJLDpzUkQkwyTl4GRFRYVbsmRJMjYtIjIn7dy585RzrnLmRyapuJcsWcKOHTuSsWkRkTnJzE7E+1gNlYiIZBgVt4hIhlFxi4hkGBW3iEiGUXGLiGQYFbeISIZRcYuIZBgVt4hIhlFxi4hkmFSux51V7tleP+n9b722LsVJRGSu0R63iEiGUXGLiGSYuIrbzD5iZvvMbK+Z3WtmuckOJiIik5uxuM2sFvhTYKNzbg3gB96c7GAiIjK5eIdKAkCemQWAfKA5eZFERGQ6Mxa3c64J+EegHjgJdDvnHj3/cWa21cx2mNmO9vb2xCcVEREgjumAZlZG9KK+lwBdwANm9nbn3HcnPs45tw3YBrBx40ZdyHIKk00T1BRBEZmNeIZKbgWOOefanXMjwEPAdcmNJSIiU4mnuOuBTWaWb2YGvBJ4KbmxRERkKvGMcW8HHgR2AS/EnrMtyblERGQKcZ3y7pz7FPCpJGcREZE46MxJEZEMo+IWEckwKm4RkQyj4hYRyTAqbhGRDKPiFhHJMCpuEZEMo+IWEckwuuZkihxq66Wpc4CAzygryGF1TYnXkUQkQ6m4U2A0Msa9z9QzODJ25r73b1nGwrJ8D1OJSKbSUEkKHGrrY3BkjLdfu5iP3X4pOQEfTx857XUsEclQKu4UeL6xi7ygn1XziyjOC7K+row9Td30DY16HU1EMpCKO8mGR8fYf7KXNbUl+H0GwOal84iMOZ451uFxOhHJRCruJDvQ2stwZIwrF549GFlZFGJldSHbj50mMqaLBYnI7Ki4k2xPYxdFoQCXVBScc//mpRX0Do6yr7nbo2QikqlU3Ek0OBLhQEt0mMRnds7XVlQXUhQKsK+5x6N0IpKpZixuM1tlZrsnfPSY2YdTkC3jnTjdz+iY4/Ka4pd9zWfGiuoiDrf1MRoZm+TZIiKTi+fSZQecc+ucc+uADUAY+EGyg80FLT1DANSU5E369ZXVhQyMRNjd0JXCVCKS6WY7VPJK4Ihz7kQywsw1rT2DlOQFycvxT/r1FVVFGPD4gfbUBhORjDbb4n4zcO9kXzCzrWa2w8x2tLeriABaugepLg5N+fW8HD918/J5/GBbClOJSKaLu7jNLAe4C3hgsq8757Y55zY65zZWVlYmKl/Giow52nuHmF+cO+3jVlUXsbeph7bewRQlE5FMN5s97juAXc651mSFmUtO9Q0RcY7qGYp7ZXURAE8cPJWKWCIyB8ymuN/CFMMk8nItPdE96Pkl0xf3gpJcKotCPH5AwyUiEp+4itvM8oFXAQ8lN87c0do9iM+gsnDqMW4AM+OmlZU8eeiUpgWKSFziKm7nXNg5N885p9P84tTSM0hFYYiAf+a3eMuqSroHRjQtUETiovW4k6S1ZzDu9bZvWF6J32c8fqCdjUvKz9x/z/b6lz32rdfWJSyjiGQmnfKeBH1Do3SGR2Yc3x5Xkh9kfV2ppgWKSFxU3ElwoKUXYMapgBNtWVWlaYEiEhcVdxKMF/dMUwEnumlldO67pgWKyExU3ElwoKWHnICP0vxg3M9ZXVOsaYEiEhcVdxIcOx2mojDnZUu5Tmd8WuATB9s1LVBEpqXiToLGjjDlBdPP357Mzauq6Bkc5TlNCxSRaai4Eywy5mjsHKB8FsMk425YWUHQbzy6ryUJyURkrlBxJ1hrzyDDkTHKCnJm/dzi3CDXLavgkX2tOKdrUYrI5FTcCdbQEQagPH/2xQ3w6tXzqe8Ic6C1N5GxRGQOUXEnWP14cV/AHjfAqy6vxgwe2atFGEVkciruBGvoCOOz6NmQF6KyKMSGujIe0Ti3iExBxZ1gDZ0DLCjJI+C78Lf2ttXVvHiyh47+4QQmE5G5QsWdYPUdYRaVT35x4Hi9evV8AF462ZOISCIyx6i4E6y+I0xdeXyrAk5l8bwCLp1fxL5mFbeIvJyKO4EGhiO09w6xKM7lXKdz2+r5nDjdT9/QaAKSichcEu8VcErN7EEz229mL5nZ5mQHy0SNndEZJXXzLr64X726Ggfs13CJiJwn3j3uzwM/d85dCqwFXkpepMzVECvuRRc5VAJw+YJiSvODGi4RkZeZsbjNrBi4Efg6gHNu2DnXleRcGan+dKy4EzBUYmasXlDMkfY+hkYiF709EZk74rl02VKgHfimma0FdgIfcs71T3yQmW0FtgLU1WXn5bXqOwbIC/qpKJzdyTeTXaIM4PKaEn5z5DQH2/q4orYkERFFZA6IZ6gkAKwH/tU5dxXQD3zs/Ac557Y55zY65zZWVlYmOGZmaOiMziixWSznOp3F8/IpyPGzr1nXaBaRs+Ip7kag0Tm3Pfb5g0SLXM7TkIA53BP5zLhsQTEHWnoZHdMa3SISNWNxO+dagAYzWxW765XAi0lNlYGcc7GTby5+fHuiS+cXMTQ6RkPHQEK3KyKZK54xboAPAt8zsxzgKPDu5EXKTJ3hEcLDERYm4MDkREsrC/EZHG7r5ZKKgoRuW0QyU1zF7ZzbDWxMbpTMdc/2epo6o3vER9v7pjzYeCFyg34WluVzqK2PV12esM2KSAbTmZMJ0jUQXRCq9ALX4Z7OiqpCmjoHCA/rLEoRUXEnTFd4BIDSvAtbznU6y6sKccCR9v4ZHysic5+KO0G6wsME/UZ+jj/h215Ylk8o4ONwm66KIyIq7oTpGhihND8nYXO4J/L7jGWVhRxq69O1KEVExZ0oXeGRpAyTjFteVUhXeITjsdPqRSR7qbgTpCs8nJQDk+NWVBUC8NSh9qS9hohkBhV3AgyPjtE/HKHsAq8zGY/yghyKcgPsPNGZtNcQkcyg4k6A8amAJUkcKjEzFpXl81xDV9JeQ0Qyg4o7AbrHpwImcagEoK48nxOnw5zqG0rq64hIelNxJ8D4HO5kDpUAZ65lubu+K6mvIyLpTcWdAJ0Dw/gMinKTW9y1ZXkEfMaueo1zi2QzFXcCdIdHKM4N4vclfg73REG/j8trilXcIllOxZ0AneERSpM8TDLuqkWl7GnsZjSi9blFspWKOwG6BpI7h3ui9YvLCA9HONCq099FspWK+yJFxhw9A8k9a3Ki9XVlAOzSAUqRrKXivkitPYOMOShJ0VDJwrI8KgpzeE7j3CJZK64LKZjZcaAXiACjzjldVCGmqSt6AYWyFA2VmBlX1ZVpSqBIFpvNHvfNzrl1Ku1zNceKO1VDJQBX1JZw9FQ/vYMjKXtNEUkfGiq5SI2xS5al6uAkwJraYgBeOqkDlCLZKN7idsCjZrbTzLZO9gAz22pmO8xsR3t79qxg19w1QH6On5xA6n4GrqkpAWBvU3fKXlNE0ke8bXO9c249cAfwATO78fwHOOe2Oec2Ouc2VlZWJjRkOmvqGkjZHO5xVcW5VBaF2Nus4hbJRnEVt3OuOfZnG/AD4JpkhsokTZ0DlOalbphk3JqaYvY19aT8dUXEezMWt5kVmFnR+G3gNmBvsoNlAucczR7scQOsqS3hUFsvA8ORlL+2iHgrnj3uauApM3seeAb4iXPu58mNlRm6B0boH46k9MDkuNU1JYw52N+ivW6RbDPjPG7n3FFgbQqyZJwzM0pSOBXwnu31AHSGoxdv+OZvjvPSyV7eem1dyjKIiLc0HfAinJnD7cFQSWlekLyg/0wGEckeKu6L0NSV+jnc48yM2tI8mrtV3CLZRsV9EZo6B8gN+ijI8Xvy+jWlubR2DzE6piVeRbKJivsiNHcPUFOah1lyL6AwlZrSPCLO0daja1CKZBMV90Vo6hygtjTPs9evib22xrlFsouK+yI0dQ16WtzlBTmEAr4zY+0ikh1U3BdocCTCqb4hT4vbZ8aCkjztcYtkGRX3BRovyxoPixugtjSXlp5BXYNSJIuouC9Qc9cgALVl3hZ3TWkeIxHH0VP9nuYQkdRRcV+gpq4wgKdDJXB2j19LvIpkDxX3BWrqHMBnML8k19McFYUhgn5jr1YKFMkaKu4L1NQ1SHVxLkG/t2+h32fML87V2twiWUTFfYGausKeD5OMqynN48XmHsbGnNdRRCQFVNwXqLFzwPMDk+NqS/PoGxrlREfY6ygikgIq7gswEhmjuWuAuvJ8r6MAOkApkm1U3BeguWuAMQeL0qS4q4rHD1CquEWyQdzFbWZ+M3vOzB5OZqBMUB8bkkiXPe6Az8dlC4rZ3dDldRQRSYHZ7HF/CHgpWUEySboVN8D6ujL2NHbrDEqRLBBXcZvZQuC1wNeSGyczNHQMkOP3UV3s7RzuidYvLmNgJML+ll6vo4hIksW7x/054KPAlLtzZrbVzHaY2Y729vZEZEtbDR1hFpbl4fd5sw73ZDYsLgNg54lOj5OISLLNWNxmdifQ5pzbOd3jnHPbnHMbnXMbKysrExYwHdV3hNPmwOS4mpJcqotD7KpXcYvMdfHscV8P3GVmx4H7gFvM7LtJTZXm6jvCaTW+DdFrUG5YXKY9bpEsMGNxO+c+7pxb6JxbArwZ+KVz7u1JT5amusMjdA+MpF1xQ/QAZWPnAG29g15HEZEk0jzuWWrojM4oSbehEoCr6qLj3LtOdHkbRESSalbF7Zx73Dl3Z7LCZIJ0nAo4bk1tMTl+n8a5ReY47XHP0nhxLypPj3VKJgoF/KypLWaXxrlF5jQV9yzVd4QpL8ihKDfodZRJbVhcxp6mbgZHIl5HEZEkUXHPUkMaTgWc6LplFQyPjvHMsQ6vo4hIkqi4ZykdpwJOtGnpPHICPh4/MLdPghLJZiruWRiNjNHUOUBdGo5vj8vL8bNp6TweP9jmdRQRSRIV9yyc7B5kdMyl9R43wJaVlRxt76dBF1YQmZNU3LNw4nT6zuGeaMuq6JIDjx/QXrfIXKTinoVjp/oAWFZZ6HGS6V1SUUBdeb7GuUXmKBX3LBxp76cgx09VUcjrKNMyM7asquS3R05rWqDIHKTinoVjp/q5pLIAs/RZznUqW1ZVMjAS0bRAkTlIxT0LR0/1cUlFeg+TjNu8tIKCHD8P72n2OoqIJJiKO05DoxEaOwdYWlHgdZS45OX4ec0VC/jJnpOEh0e9jiMiCaTijtOJ02Gcg6WVmVHcAG/auIj+4Qg/faHF6ygikkABrwNkiqPt0RklS9N0qOSe7fUvu+8t1yxiybx8HtjRwBs3LPQglYgkg/a443T0VD8ASyrSew73RGbGGzcsZPuxDupP62QckblCe9xxOtreT1VRKG1XBZzK761fyD89dpAHdzbwZ7etAibfO3/rtXWpjiYiF2jG4jazXOAJIBR7/IPOuU8lO5jXzi+3Z451ZNT49ria0jxuWFHJ/Tsa+MAtywkF/F5HEpGLFM9QyRBwi3NuLbAOuN3MNiU1VRo61TeUMVMBz/feV1xCa88QP3pOUwNF5oIZ97idcw7oi30ajH24ZIZKN+GhUcLDEbrDw5MOM6S7G1ZUsLqmmC8/cYT/qoOUIhkvrjFuM/MDO4HlwBedc9snecxWYCtAXd3cGi891TcEQEVhep/qfr6JP2SuqC3hvmcb+Osf7mVNbYmHqUTkYsU1q8Q5F3HOrQMWAteY2ZpJHrPNObfRObexsrIywTG9dapvGICKNF+jZDpraksoL8jhiUPtRH+JEpFMNdurvHcBjwO3JyNMumrvG8JnUJaf43WUC+Yz48YVlTR2DnCkvd/rOCJyEWYsbjOrNLPS2O084FZgf5JzpZX23iHmFYTw+9J/canpXFVXSnFugF/u1zrdIpksnj3uBcCvzGwP8CzwmHPu4eTGSi+tPYNUFWfuMMm4oN/HDSsqOX66n2OntNctkqlmLG7n3B7n3FXOuSudc2ucc59NRbB0MRIZo6N/mOriXK+jJMTVS8opCAX4la6OI5KxdMr7DNp7h3AwZ4o7J+DjhuUVHG7r0zUpRTKUinsGrT2DAFRn8IyS8117STl5Qb/2ukUylIp7Bq09Q/jNmJdhc7inEwr6uX55BftbemnuGvA6jojMkop7Bm29g1QU5WT8jJLzXbdsHrlBn/a6RTKQinsGrT2Dc2Z8e6LcoJ/NS+exr7nnzHCQiGQGFfc0hkYjdIZHqCqae8UNcP2yCnIC2usWyTQq7mm09UTXKJk/B+ZwTyY/FGDTJeW80NjNcc3rFskYKu5ptPVGhxCq5uBQybjrl1fg9xlfeeKI11FEJE4q7mm09gwR8BnlBZm7RslMinKDbFhcxoM7G2np1li3SCZQcU+jtWeQqqIQPptbM0rOd8OKSsYcfO3Jo15HEZE4qLinMVdnlJyvvCCH1125gHueqaezf9jrOCIyAxX3FMLDo/QMjs7p8e2J3rdlOeHhCN9++rjXUURkBiruKZyMjffWlGRHca+aX8Stl1Xzzd8cp39o1Os4IjINFfcUxot7fpYUN8D7b15G98AI9z6TedfVFMkmKu4pnOwaoCg3QFFu0OsoKbO+roxNS8v56pNHGRqNeB1HRKag4p7Cye5BFmTR3va4929ZTmvPEA/tavI6iohMIZ5Lly0ys1+Z2Utmts/MPpSKYF4aHInQ1jtITUme11FS7oYVFVxRW8KXHj/M8OiY13FEZBLx7HGPAn/unLsM2AR8wMwuT24sbx1u62PMwYLS7CtuM+PPb1tJQ8cA39t+wus4IjKJeC5ddtI5tyt2uxd4CahNdjAvvdjcA5CVQyUAN62s5Lpl8/iXXx6md3DE6zgicp5ZjXGb2RLgKmB7UtKkiX3N3eQEfHP6VPfpmBkfv+MyOvqH+cqvdTalSLqJu7jNrBD4PvBh51zPJF/famY7zGxHe3t7IjOm3Isne1hQnDvnT3WfzhULS3jd2hq+9tRRrWEikmbiKm4zCxIt7e855x6a7DHOuW3OuY3OuY2VlZWJzJhSY2OOl072sqA0O4dJJvroq1fhHPzPn7zodRQRmSCeWSUGfB14yTn3f5MfyVsNnWH6hkZZkIUzSs63qDyfP7l5OT/Zc5InDmb2b1Eic0k8e9zXA+8AbjGz3bGP1yQ5l2f2ZfmByfOV5AWZV5DDR+7fzbd/e5x7tuusShGvxTOr5CnnnDnnrnTOrYt9/DQV4bywp7GboN+yYlXAeAT8Pu5aV8Pp/mGeOKS9bpF0EPA6QLp5vqGLyxYUE/Rn10ml0+1Jr6gq4oraEn59oJ11C0tTF0pEJpVd7TSDyJhjT2MX6xaVeh0l7bz2igX4fcaP9zTjnPM6jkhWU3FPcKS9j/7hCGu1V/kyxXlBbr2smoOtfTyyr8XrOCJZTcU9we76LgDWao97UpuWzmNBSS6f+fGLWrNbxEMq7gl2N3ZRlBtgaUWB11HSkt9nvH5tDSe7B/n8Lw55HUcka6m4J3i+oYu1C0vx+bL3jMmZ1M0r4M1XL+LrTx3jQEuv13FEspJmlcQMDEfY39LL+25a5nWUtLe8spBQwMfW7+xg6w1LsdjSAG+9ts7jZCLZQXvcMfuau4mMOY1vxyE/FOD21fM5cTrMc7HjAiKSOirumN0NXQCsXVTibZAMsX5xGXXl+fxs70nCwzpQKZJKKu6Y3Q1d1JbmUVWkMybj4TPj9etqGBiJ8Oi+Vq/jiGQVFTfgnGPniU7W1ZV6HSWjLCjJY/PSeTx7vIOGjrDXcUSyhoobOHE6zMnuQTYtned1lIzzysuqKcoN8KPdTUTGdEalSCqouIGnj54GYLOKe9Zyg35ec8UCmrsH+e7vdI1KkVTQdEDg6SOnqSwKsaxSJ95ciCtqS9hxopN/fOQAd1wxP67jBJMtaqXphCLxyfo9buccTx89zeal887MR5bZMTPuWlvD0OgYf/eTl7yOIzLnZX1xH2nvp713iM3LNExyMSoKQ/zxlmX8cHczP33hpNdxROa0rC9ujW8nzgduXsZVdaX8xQPPs7/lZdeTFpEEieeak98wszYz25uKQKn2uyOnmV+cy+J5+V5HyXihgJ8vv30DhaEAW/9tJ13hYa8jicxJ8exxfwu4Pck5POGc43dHT7N5mca3E6W6OJevvGMDLd2DvOnLT3OoVQtRiSRaPNecfALoSEGWlNvf0svp/mENkyTYVXVlfOvdV9MZHuauL/yG7/7uBIMjEa9jicwZCRvjNrOtZrbDzHa0t2fGRWUf2deCGWy5tNLrKHPOdcsr+Omf3sDaRSV88od7ueZv/5P/8YMX+PXBdpW4yEVK2Dxu59w2YBvAxo0bM+IUup/vbeHqxeVanyRJqopzuee9m/jtkdN8f1cjD+1q5J7t9YQCPlZUF3HTikpqy/K8jimScbL2BJwj7X3sb+nlU6+73Osoc5rPZ7xiRQWvWFHB3/2XK9h+7DSPH2jnvmfr2dvUzYqqQt5wVS1l+TleRxXJGFlb3D/fG73g7e1r5nucJHvk5fjZsqqKLauqqCvP55ljHfzqQBtf+OVhfv/qRV7HE8kYMxa3md0LbAEqzKwR+JRz7uvJDpZsP33hJFfVlbKgRL+qJ8psTmPPDfq5cWUll9cUc8/2er792+PUlefzB6+4JNkxRTLejMXtnHtLKoKkUv3pMPuae/jEay7zOsqcN1mZT1RRGOKPb1rGv+9o4LMPv4jP4F3Xq7xFppOVQyU/3Rs9JVvDJOkhJ+DjLdfU8cShdj794xcJ+H28fdNir2OJpK2sO+U9Mua4Z3s9GxaXsahcZ0umC7/P+MJbr+KWS6v45A/3cv+z0++pi2SzrCvuR/e1UN8R5r0aS007oYCfL71tPTeurORjD73A93c2eh1JJC1lXXF/9cmj1JXnc9tqDZOko9ygn23v2MB1y+bxlw8+z492N3kdSSTtZNUY984THeyq7+Izd63G74uuTTLTwTNJnYn/Fq+6bD7NXYN85P7dBHw+XnvlAg+TiaSXrNrj/uoTxyjJC/KmjQu9jiIzyAn4+O+bF7OoPJ8P3fccD+9p9jqSSNrImj3uHcc7eGRfCzetquSHz6kEMkEo4Oddm5fw8Asn+ZN7nuOpQ6f45J2XUxia+ttWl0STbJAVe9yDIxH+6vt7KMkPctNKLSiVSUJBP/f84bW8b0t0rver/98TfPFXh2nsDE/5nMiYY8xlxHI5IhckK/a4v/Srwxxp7+dd1y0hFPB7HUdmKRTw81e3X8orL63i73++n7sfOcDdjxygojCHsvwccoN++odG6R0apSs8zEjE4TMoyg1Slh+ktWeQm1ZVsm5hKT6f1l2XzGcuCXsmGzdudDt27Ej4di/E3qZu3vDF33DX2ho2Lin3Oo5cgPOHOho6wvyvn7xER/8w4eFRRiJjhAJ+coN+cgM+coI+IhFHz+AIbb1DNHUN4BzUlefztmvr+G8bF1FWoEWtJL2Y2U7n3MZ4Hjun97gbOsK8+1vPUlEY4q/vvJyfxRaWksy2qDx/VkNed6yZz+MH27j3mQb+98/280+PHeR1V9bwjs2LWbuwRFc/kowzZ4v7VN8Q7/j6doZHx3jgjzdrDyuLjf/AfsO6WjYtncf2o6f58Z5mvr+rkStqS3jHpsXcuXYB+Tlz9r+DzDFzcqjkxOl+3vvtHTR0hvneezexYXEZoDnbctbQSIRAwMd3nj7OwdY+QgEfr1hewZZLq1i3sJSV8wt1PERSKquHSn59sJ0/+s4ODONt1y7mQEsvB1p0wVo5VygYLeV3bl7C8dNh9jZ1s6u+k1/sbwMg4DNWVBexpqaYy2uKWVldxIrqQioLQxpaEc/NmT3u7vAIdz+6n+9tr6e6KJe3b1pMuYZHZBacc3T0D9PcPUhz18CZj/7hs9fIzAv6qS4OUVWcy2uvWMCK6kJWVhdRURjyMLnMBVm1xz0wHOGBnQ18/j8P0Rke5p2bl7BkXgE5gayYoi4JZGbMKwwxrzDEFbUlQLTMe4dGaesZorVnkLbeQVp7htjT2MUzxzrOPLe8IIcVVdES7wwPU5IXpCQvSHFekMJQQMvUSkLFVdxmdjvwecAPfM0593+SmmoGzjleaOrmpy+0cN+z9XSFR7h6SRmfvusaVteUaCxbEsbMKM4NUpwbZHlV4Zn7nXO88rJqDrb2crC1l0OtfRxs6+UHzzXRNzR6zjZ8Bv/6+BEWlOQyvySXmtI85hfnnvN5RWHozPo5F2NwJELv4Cj3bq/HLLpcbsDvI+Az3rapjhy/L+uHeqbqh0w6wzaeS5f5gS8CrwIagWfN7D+ccy8mI5BzjpGIY2g0wtDoGIMjEU71DdPaM8jhtj5ebO5h54lOWnoG8Rncelk1W29cyobFZVn/DSmpY2bMjxXvjROmJjrn+OqTx+geGKFnYITu2Ed5QQ4nuwfY29TNYy+2MjQ6ds72/D6jqihEWX4OJXlBSvOjHwWxmS5jDhwO52A4MkbPwAg9g6OxP0foGRilZ3CE4fO2O9FnH36RgM/Iz/FTEApEP2K383P8BHw+fL7o381nhs/OnoUaGXNExjhz++x9jqDfd+a3i5LzPorzxl8nQEHIT2EoQCjgx+cj+npGQv7fjo05hkbHCA+PMjASYWA4Qng4cua96R08+z7tONHB4MgYA8MRBkciOCAU8PHrg20U5ATID/kpyg1SGvt3iP5dcs78m+QHA/j9RsBn+H2G3yzlJ3bFs8d9DXDYOXcUwMzuA14PJLy4137mUXoGR5hu2H1ReR4bFpdx86VV3HJplcaxxTNT7bkVhgIUhgLUlk5+PVPnHAPDEboHzxZ7tOhHGRgeZXRsjMNtfXQNjNA/NIoRLTcDsGjJFOcGKcoLEh4apSAnwLyCEHlBX/QkpKCfUGyoMDLmGI19rK4pJjw8Sv9QhP6hUcLDEfqGRjl+up/h0TEiYw4HOAdFuQHGnDtT4NFSN7oHhvHFsvjMMDMiY2MMjIwxMBJhcDhCZJbHzXyx3wx8sR8Y4z+gzmxlwg8tF3v/YndP2xVTvVYo4Ccvx09u0EduwI9Z9DeV46fChEei70/PwAijY/FvfPw9qiwK8ZuP3TK7UBcgnuKuBRomfN4IXHv+g8xsK7A19mmfmR24+HgAVACnxj85ATwFfClBG79A52RKI+mYKx0zQXrmSsdMkJ650jETh6DCPn7BueI+EBJPcU/2O8DLfhQ557YB2+J94XiZ2Y54j7SmSjpmgvTMlY6ZID1zpWMmSM9c6ZgJUpcrnqkXjcCiCZ8vBLQuqoiIR+Ip7meBFWZ2iZnlAG8G/iO5sUREZCozDpU450bN7E+AR4hOB/yGc25f0pOdlfDhlwRIx0yQnrnSMROkZ650zATpmSsdM0GKciXlzEkREUkenV4oIpJhVNwiIpnGOZeWH8DtwAHgMPCxBG3zG0AbsHfCfeXAY8Ch2J9lE7728djrHwBePeH+DcALsa/9M2eHnELA/bH7twNLJjznnbHXOAS887xci4BfAS8B+4APeZ0NyAWeAZ6PZfqM15kmfM0PPAc8nEaZjse2txvYkQ65gFLgQWA/0e+tzWmQaVXsPRr/6AE+nAa5PkL0+3wvcC/R73/Pv6+m7LJEFGKiP4j+xzwCLAVyiJbH5QnY7o3Aes4t7n8g9oMB+Bjw97Hbl8deNwRcEsvjj33tmdh/AgN+BtwRu//9wJdjt98M3D/hP/DR2J9lsdsTvwkWAOtjt4uAg7HX9yxb7PmFsccEY99sm9Lk/foz4B7OFnc6ZDoOVJz3/eZpLuDbwHtjt3OIFrnn79V5/89biJ544uX3ei1wDMiLPe7fgXel03v1svfO65KeomA3A49M+PzjwMcTtO0lnFvcB4AFEwr0wGSvSXRWzebYY/ZPuP8twFcmPiZ2O0D0zC6b+JjY174CvGWajD8iujZMWmQD8oFdRM+Y9TQT0fMIfgHcwtni9vx9YvLi9iwXUEy0jCxdMk3yfX4b8Buvc3H27PDy2OMfjmVLm/fq/I90HeOe7DT72iS9VrVz7iRA7M+qGTLUxm5Plu3Mc5xzo0A3MG+abb2MmS0BriK6h+tpNjPzm9luosNLjznnPM8EfA74KDBxNSWvM0H0bOJHzWxnbPkHr3MtBdqBb5rZc2b2NTMrSJP3atybiQ5L4GUu51wT8I9APXAS6HbOPeplJmaQrsUd12n2HmWYLtuFPOfsC5oVAt8HPuyc6/E6m3Mu4pxbR3Qv9xozW+NlJjO7E2hzzu2cJkdKM024fb1zbj1wB/ABM7vR41wBosOC/+qcuwroJ/rrvpeZzr5Y9GS+u4AHpsmUklxmVkZ04bxLgBqgwMze7mWmaV4bSN/iTuVp9q1mtgAg9mfbDBkaY7cny3bmOWYWAEqAjmm2dYaZBYmW9veccw+lUzbnXBfwONEDxl5muh64y8yOA/cBt5jZd9PhfXLONcf+bAN+QHRVTS9zNQKNsd+SIHqQcn06vFcxdwC7nHOtsc+9zHUrcMw51+6cGwEeAq7zONP0ZhpL8eKD6N7CUaI/AccPTq5O0LaXcO4Y992cewDiH2K3V3PuAYijnD0A8SzRA3XjByBeE7v/A5x7AOLfY7fLiY43lsU+jgHlEzIY8G/A587L6lk2oBIojT0mD3gSuDMd3q/YY7Zwdozb00xAAVA04fZvif6Q8zrXk8Cq2O1Px/Kky7/ffcC70+R7/VqiM0ryY9v6NvDBdHmvJu0xr0t6moJ9DdHZFUeATyRom/cSHcMaIfqT7j1Ex5l+QXQqzi84t1A/EXv9A8SODsfu30h02tAR4AucnfKTS/RXv8NEjy4vnfCcP4jdf3jiN2zsa68g+uvRHs5Ok3qNl9mAK4lOudsT297fxO73/P2KfX0LZ4vb00xEx5Of5+zUyU+kSa51wI7Yv+EPiRaD5/9+RAvyNFAy4T6v36vPEJ02uRf4DtFS9vy9mupDp7yLiGSYdB3jFhGRKai4RUQyjIpbRCTDqLhFRDKMiltEJMOouCVtmdknzGyfme0xs91mdu00j/2Wmb1xhu19y8yOxba1y8w2T/G4z5rZrRebXyRZZrx0mYgXYqV6J9FVE4fMrILoyVgX6y+dcw+a2W1EF/S58rzX9Tvn/iYBryOSNNrjlnS1ADjlnBsCcM6dcs41m9nfmNmzZrbXzLaZ2cvWejCzDWb269iCT4+Mn7Z8nieA5bHHH49t9yngTRP33s3sajP7rZk9b2bPmFlRbPGtu2M59pjZHyXvbRB5ORW3pKtHgUVmdtDMvmRmN8Xu/4Jz7mrn3Bqip+LfOfFJsTVf/gV4o3NuA9GLZ/ztJNt/HdEF78cNOude4Zy7b8K2cogufv8h59xaomtaDBA947bbOXc1cDXwh2Z2SQL+ziJx0VCJpCXnXJ+ZbQBuAG4G7jezjwG9ZvZRoqdNlxM9xfzHE566ClgDPBbbGfcTXeZg3N1m9kmiS56+Z8L9908SYxVw0jn3bCxTD0BsmOXKCWPqJcAKoutMiCSdilvSlnMuQnRVwsfN7AXgj4iOSW90zjWY2aeJrgExkQH7nHOTHngkNsY9yf39k9xnTL7EpgEfdM49MvPfQiTxNFQiacnMVpnZigl3rSO6oA/Aqdja5ZPNIjkAVI7PGDGzoJmtvsAY+4EaM7s6tq2i2JKcjwDviw3LYGYrYxcpEEkJ7XFLuioE/sXMSoFRoiunbQW6iI5NHye6hOY5nHPDsSGMfzazEqLf458jOqQyK7Ft/X4sRx7R8e1bga8RXR54V+zgaDvwhtluX+RCaXVAEZEMo6ESEZEMo+IWEckwKm4RkQyj4hYRyTAqbhGRDKPiFhHJMCpuEZEM8/8BBaPY76M7EYUAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# check distribution of target variable\n",
    "sns.distplot(train_df['SalePrice'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.880940746034036"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# there is a right skew, what's the value?\n",
    "stats.skew(train_df['SalePrice'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.12122191311528363"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# what if we apply a log transformation?\n",
    "sns.distplot(np.log1p(train_df['SalePrice']))\n",
    "plt.show()\n",
    "stats.skew(np.log1p(train_df['SalePrice']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PoolQC          0.995205\n",
       "MiscFeature     0.963014\n",
       "Alley           0.937671\n",
       "Fence           0.807534\n",
       "FireplaceQu     0.472603\n",
       "LotFrontage     0.177397\n",
       "GarageCond      0.055479\n",
       "GarageType      0.055479\n",
       "GarageYrBlt     0.055479\n",
       "GarageFinish    0.055479\n",
       "dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we will apply the log transformation when making models\n",
    "\n",
    "# let's remove variables with high null values\n",
    "null_rate = train_df.isna().sum() / train_df.shape[0]\n",
    "null_rate.sort_values(ascending=False, inplace=True)\n",
    "null_rate.iloc[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove above 30%\n",
    "drop = ['PoolQC', 'MiscFeature', 'Alley', 'Fence', 'FireplaceQu']\n",
    "train_df.drop(drop, axis=1, inplace=True)\n",
    "submission_df.drop(drop, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# there are some obvious features that can be created from the data\n",
    "def feature_engineering(x):\n",
    "    # difference between built and sold\n",
    "    x['HouseAge'] = x['YrSold'].fillna(0) - x['YearBuilt'].fillna(0)\n",
    "    # finished area of basement\n",
    "    x['BsmtFinishedSF'] = x['TotalBsmtSF'].fillna(0) - x['BsmtUnfSF'].fillna(0)\n",
    "    # total finished area\n",
    "    x['GrFinishedSF'] = x['GrLivArea'].fillna(0) - x['LowQualFinSF'].fillna(0)\n",
    "    # total full baths\n",
    "    x['TotalFullBaths'] = x['BsmtFullBath'].fillna(0) + x['FullBath'].fillna(0)\n",
    "    # total half batchs\n",
    "    x['TotalHalfBaths'] = x['BsmtHalfBath'].fillna(0) + x['HalfBath'].fillna(0)\n",
    "    # total porch+deck area\n",
    "    x['TotalPorchDeckArea'] = x[['WoodDeckSF', 'OpenPorchSF', 'EnclosedPorch', '3SsnPorch', 'ScreenPorch']].fillna(0).sum(axis=1)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add features created\n",
    "train_df = feature_engineering(train_df)\n",
    "submission_df = feature_engineering(submission_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some functions to plot distributions/scatter plots\n",
    "def plot_numeric_distribution(data, variable: str, bins=50):\n",
    "    \"\"\"\n",
    "    Plot distribution of variable.\n",
    "    \"\"\"\n",
    "    # set up two subplots\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(15, 7))\n",
    "    ax = ax.flatten()\n",
    "    # one a simple distribution plot\n",
    "    sns.distplot(data[variable], bins=bins, ax=ax[0])\n",
    "    ax[0].set_title('Distribution')\n",
    "    # do a cumulative dist\n",
    "    sns.distplot(data[variable], bins=bins, hist_kws={'cumulative': True}, kde_kws={'cumulative': True})\n",
    "    ax[1].set_title('Cumulative Distribution')\n",
    "    # title\n",
    "    fig.suptitle(variable, fontsize=14)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def bootstrap(x, fraction: float=0.3, times: int=300, alpha=0.05):\n",
    "    \"\"\"\n",
    "    Samples x multiple times and returns mean, and upper and lower bounds of alpha.\n",
    "    \"\"\"\n",
    "    arr = np.zeros(times)\n",
    "    size = x.shape[0]\n",
    "    sample_size = int(size * fraction)\n",
    "    for i in range(times):\n",
    "        # sample\n",
    "        s = np.random.choice(x, size=sample_size, replace=False).mean()\n",
    "        # calculate mean\n",
    "        arr[i] = s\n",
    "    # return actual mean, calculated mean, and upper/lower bounds\n",
    "    lower, median, upper = np.quantile(arr, [alpha / 2, 0.5, 1 - alpha / 2])\n",
    "    return pd.Series({\n",
    "        'actual mean': x.mean(), 'bootstrap mean': arr.mean(), \n",
    "        'bootstrap median': median, 'lower bound': lower, 'upper bound': upper})\n",
    "\n",
    "\n",
    "def plot_categorical_distribution(data, variable: str, max_display: int=20, return_data=False):\n",
    "    \"\"\"\n",
    "    Plot distribution of categorical variable - along with confidence bounds.\n",
    "    \"\"\"\n",
    "    # for each value, including NaN, create column\n",
    "    save = pd.DataFrame()\n",
    "    for value in data[variable].unique():\n",
    "        if value is np.nan:\n",
    "            save['_nan'] = data[variable].isna().astype(int)\n",
    "        else:\n",
    "            save[value] = (data[variable] == value).astype(int)\n",
    "    # for each column, apply bootstrap\n",
    "    result = save.apply(bootstrap, axis=0).T\n",
    "    \n",
    "    # if result size is greater than max_display, cap it\n",
    "    copy = None\n",
    "    if result.shape[0] > max_display:\n",
    "        print('Reducing Size.')\n",
    "        copy = result.copy(deep=True)\n",
    "        result.sort_values('bootstrap mean', ascending=False, inplace=True)\n",
    "        result = result.iloc[:max_display]\n",
    "    \n",
    "    # create plot\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(15, 7))\n",
    "    # plot bootstrap mean\n",
    "    ax.bar(result.index, result['bootstrap mean'])\n",
    "    lower_bound = result['bootstrap mean'] - result['lower bound']\n",
    "    upper_bound = - result['bootstrap mean'] + result['upper bound']\n",
    "    ax.errorbar(result.index, result['bootstrap mean'], yerr=[lower_bound, upper_bound], linestyle='', color='black')\n",
    "    ax.set_title(variable, fontsize=15)\n",
    "    plt.show()\n",
    "    if return_data:\n",
    "        if copy is not None:\n",
    "            return copy\n",
    "        else:\n",
    "            return result\n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "def plot_scatter(data: pd.DataFrame, x: str, y: str, categorical: bool) -> None:\n",
    "    \"\"\"\n",
    "    Produces a scatter plot for x vs y - y should be numeric!\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(15, 7))\n",
    "    if not categorical:\n",
    "        plt.scatter(data[x], data[y])\n",
    "        plt.title('{} vs {} Scatterplot'.format(x, y))\n",
    "        plt.show()\n",
    "    elif categorical:\n",
    "        sns.boxplot(y=data[y], x=data[x].fillna('_nan'))\n",
    "        plt.title('{} vs {} Scatterplot'.format(x, y))\n",
    "        plt.show()\n",
    "    else:\n",
    "        raise Exception('Invalid categorical bool')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a summarizing to plot both, distribution and scatter\n",
    "def plot_dist_and_scatter(data, x, y, categorical):\n",
    "    if categorical:\n",
    "        plot_categorical_distribution(data, x)\n",
    "        plot_scatter(data, x, y, categorical=True)\n",
    "    else:\n",
    "        plot_numeric_distribution(data, x)\n",
    "        plot_scatter(data, x, y, categorical=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "limits = {\n",
    "    'BsmtFinSF1': [0, 3000],\n",
    "    'BsmtFinSF2': [0, 1200],\n",
    "    'TotalBsmtSF': [0, 4000],\n",
    "    '1stFlrSF': [0, 4000],\n",
    "    'GrLivArea': [0, 4000],\n",
    "    'BsmtFullBath': [0, 2],\n",
    "    'BsmtHalfBath': [0, 1],\n",
    "    'BedroomAbvGr': [0, 6],\n",
    "    'KitchenAbvGr': [1, 2],\n",
    "    'TotRmsAbvGrd': [3, 12],\n",
    "    'GarageArea': [0, 1300],\n",
    "    'WoodDeckSF': [0, 800],\n",
    "    'OpenPorchSF': [0, 500],\n",
    "    'EnclosedPorch': [0, 500],\n",
    "    '3SsnPorch': [0, 500],\n",
    "    'ScreenPorch': [0, 450],\n",
    "    'BsmtFinishedSF': [0, 3000],\n",
    "    'GrFinishedSF': [0, 4000],\n",
    "    'TotalFullBaths': [1, 6],\n",
    "    'TotalHalfBaths': [0, 2],\n",
    "    'TotalPorchDeckArea': [0, 900]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's apply the various limits\n",
    "def outliers(rules, data):\n",
    "    rules_list = []\n",
    "    for k, v in rules.items():\n",
    "        cond = (data[k] >= v[0]) & (data[k] <= v[1])\n",
    "        rules_list.append(cond)\n",
    "    return rules_list\n",
    "\n",
    "outlier_ids = train_df.loc[~pd.concat(outliers(limits, train_df), axis=1).apply(np.all, axis=1), 'Id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we want to encode categoricals as binary, ordinal, or one hot encode if necessary, and lastly numeric\n",
    "feature_encoding = {\n",
    "    'ordinal': {'ExterQual': ['Po', 'Fa', 'TA', 'Gd', 'Ex'], 'ExterCond': ['Po', 'Fa', 'TA', 'Gd', 'Ex'],\n",
    "                'BsmtQual': ['Po', 'Fa', 'TA', 'Gd', 'Ex'], 'BsmtCond': ['Po', 'Fa', 'TA', 'Gd', 'Ex'],\n",
    "                'BsmtExposure': ['No', 'Mn', 'Av', 'Gd'], 'BsmtFinType1': ['Unf', 'LwQ', 'Rec', 'BLQ', 'ALQ', 'GLQ'],\n",
    "                'BsmtFinType2': ['Unf', 'LwQ', 'Rec', 'BLQ', 'ALQ', 'GLQ'], 'HeatingQC': ['Po', 'Fa', 'TA', 'Gd', 'Ex'],\n",
    "                'KitchenQual': ['Po', 'Fa', 'TA', 'Gd', 'Ex'], 'GarageFinish': ['Unf', 'RFn', 'Fin'],\n",
    "                'GarageQual': ['Po', 'Fa', 'TA', 'Gd', 'Ex'], 'GarageCond': ['Po', 'Fa', 'TA', 'Gd', 'Ex']},\n",
    "    'onehot': ['MSSubClass', 'MSZoning', 'Street', \n",
    "               'LandContour', 'LotShape', 'LotConfig', \n",
    "               'LandSlope', 'Neighborhood', 'Condition1',\n",
    "               'BldgType', 'HouseStyle', 'OverallCond',\n",
    "               'RoofStyle', 'Exterior1st', 'Exterior2nd',\n",
    "               'MasVnrType', 'Foundation', 'BsmtExposure',\n",
    "               'GarageType', 'PavedDrive', 'MoSold',\n",
    "               'SaleType', 'SaleCondition'],\n",
    "    'binary': {'OverallCond': 5, 'CentralAir': 'Y', 'Electrical': 'SBrkr'},\n",
    "    'numeric': ['LotFrontage', 'LotArea', 'OverallQual', \n",
    "                'YearBuilt', 'YearRemodAdd', 'MasVnrArea',\n",
    "                'BsmtFinSF1', 'BsmtFinSF2', 'BsmtUnfSF',\n",
    "                'TotalBsmtSF', '1stFlrSF', '2ndFlrSF',\n",
    "                'GrLivArea', 'BsmtFullBath', 'BsmtHalfBath',\n",
    "                'FullBath', 'HalfBath', 'BedroomAbvGr',\n",
    "                'KitchenAbvGr', 'TotRmsAbvGrd', 'Fireplaces',\n",
    "                'GarageCars', 'GarageArea', 'WoodDeckSF',\n",
    "                'OpenPorchSF', 'EnclosedPorch', '3SsnPorch',\n",
    "                'ScreenPorch', 'HouseAge', 'BsmtFinishedSF',\n",
    "                'GrFinishedSF', 'TotalFullBaths', 'TotalHalfBaths'],\n",
    "    'remove': ['Utilities', 'Condition2', 'RoofMatl',\n",
    "               'Heating', 'LowQualFinSF', 'Functional',\n",
    "               'GarageYrBlt', 'PoolArea', 'MiscVal',\n",
    "               'YrSold']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove columns\n",
    "train_df.drop(feature_encoding['remove'], axis=1, inplace=True)\n",
    "submission_df.drop(feature_encoding['remove'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply ordinal encodings\n",
    "def apply_ordinal_encoding(encodings, data):\n",
    "    # since we don't want to modify the original dataset, return a new one\n",
    "    save = pd.DataFrame(index=data.index)\n",
    "    for k, v in encodings.items():\n",
    "        # prepare a mapping for each\n",
    "        mapping = {category: integer + 1 for integer, category in enumerate(v)}\n",
    "        # mapping will be a dict like {cat1: 1, cat2: 2...}\n",
    "        \n",
    "        # now apply that mapping to data\n",
    "        save[k] = data[k].map(mapping).fillna(0)\n",
    "        \n",
    "    return save\n",
    "\n",
    "# create a new dataframe for modeling\n",
    "X_train = apply_ordinal_encoding(feature_encoding['ordinal'], train_df)\n",
    "X_submission = apply_ordinal_encoding(feature_encoding['ordinal'], submission_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply binary encoding\n",
    "def apply_binary_encoding(encodings, data):\n",
    "    # instead of modifying the original, return a new dataframe\n",
    "    save = pd.DataFrame(index=data.index)\n",
    "    for k, v in encodings.items():\n",
    "        # if string\n",
    "        if isinstance(v, str):\n",
    "            save[k + '__{}'.format(v)] = (data[k] == v).astype(int)\n",
    "        # else it's a number\n",
    "        else:\n",
    "            save[k + '__gte_{}'.format(v)] = (data[k] >= v).astype(int)\n",
    "            \n",
    "    return save\n",
    "\n",
    "# get the encoding and add to data\n",
    "X_train = pd.concat([X_train, apply_binary_encoding(feature_encoding['binary'], train_df)], axis=1)\n",
    "X_submission = pd.concat([X_submission, apply_binary_encoding(feature_encoding['binary'], submission_df)], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply one hot encoding\n",
    "class MyOneHotEncoder(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, columns, threshold=0.05):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        columns: list\n",
    "            List of columns to apply one-hot encoding on\n",
    "        threshold: float\n",
    "            Minimum proportion required for a category to appear\n",
    "        \"\"\"\n",
    "        self.columns = columns\n",
    "        self.threshold = threshold\n",
    "        self.categories = {}\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        # make sure X has all columns\n",
    "        if not np.all(list(map(lambda x: x in X.columns, self.columns))):\n",
    "            raise Exception(\"\"\"Error while fitting. Passed data does not have all columns to be transformed.\"\"\")\n",
    "        \n",
    "        # get size\n",
    "        size = X.shape[0]\n",
    "        \n",
    "        # loop through columns\n",
    "        for c in self.columns:\n",
    "            # get value counts\n",
    "            vc = X[c].value_counts() / size\n",
    "            # for all values that are above threshold add to categories\n",
    "            eligible = vc[vc >= self.threshold].index.tolist()\n",
    "            # add\n",
    "            if len(eligible) > 0:\n",
    "                self.categories[c] = eligible\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        # make sure X has all columns that actually will be transformed\n",
    "        if not np.all(list(map(lambda x: x in X.columns, self.categories.keys()))):\n",
    "            raise Exception(\"\"\"Error while transforming. Passed data does not have all columns to be transformed.\"\"\")\n",
    "        \n",
    "        # list to save all transformations\n",
    "        save = []\n",
    "        \n",
    "        # loop\n",
    "        for k, v in self.categories.items():\n",
    "            # get binary 1, 0 for each category\n",
    "            categories = pd.concat(list(map(lambda x: (X[k] == x).astype(int), v)), axis=1)\n",
    "            # change column names to add prefix\n",
    "            categories.columns = [k + '__{}'.format(x) for x in v]\n",
    "            # add to save\n",
    "            save.append(categories)\n",
    "        \n",
    "        # return\n",
    "        return pd.concat(save, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit on training data\n",
    "myOneHotEncoder = MyOneHotEncoder(columns=feature_encoding['onehot']).fit(train_df)\n",
    "\n",
    "# get the transformation and append\n",
    "X_train = pd.concat([X_train, myOneHotEncoder.transform(train_df)], axis=1)\n",
    "X_submission = pd.concat([X_submission, myOneHotEncoder.transform(submission_df)], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lastly add numeric columns\n",
    "X_train = pd.concat([X_train, train_df[feature_encoding['numeric']]], axis=1)\n",
    "X_submission = pd.concat([X_submission, submission_df[feature_encoding['numeric']]], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# impute using medians - which would adjust for outliers\n",
    "impute = SimpleImputer(strategy='median').fit(X_train)\n",
    "\n",
    "# transform\n",
    "X_train = pd.DataFrame(impute.transform(X_train), index=X_train.index, columns=X_train.columns)\n",
    "X_submission = pd.DataFrame(impute.transform(X_submission), index=X_submission.index, columns=X_submission.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\software-installs\\anaconda3\\envs\\tensorflow-gpu-2\\lib\\site-packages\\numpy\\core\\_methods.py:205: RuntimeWarning: overflow encountered in multiply\n",
      "  x = um.multiply(x, x, out=x)\n"
     ]
    }
   ],
   "source": [
    "# overall scaling\n",
    "scaling = PowerTransformer().fit(X_train)\n",
    "\n",
    "# apply\n",
    "X_train_scaled = pd.DataFrame(scaling.transform(X_train), index=X_train.index, columns=X_train.columns)\n",
    "X_submission_scaled = pd.DataFrame(scaling.transform(X_submission), index=X_submission.index, columns=X_submission.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1460, 92), (1460, 121))"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's do some additional transformations and test those\n",
    "\n",
    "# PCA\n",
    "pca = PCA(n_components=0.99).fit(X_train_scaled)\n",
    "\n",
    "# apply\n",
    "X_train_transformed = pd.DataFrame(pca.transform(X_train_scaled), index=X_train.index)\n",
    "X_submission_transformed = pd.DataFrame(pca.transform(X_submission_scaled), index=X_submission.index)\n",
    "\n",
    "# components?\n",
    "X_train_transformed.shape, X_train_scaled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KMeans\n",
    "kmeans = KMeans(random_state=11, n_clusters=4, tol=1e-7).fit(X_train_scaled)\n",
    "scaler = PowerTransformer().fit(kmeans.predict(X_train_scaled).reshape(-1, 1))\n",
    "\n",
    "# apply\n",
    "X_train_transformed = X_train_scaled.copy(deep=True)\n",
    "X_train_transformed['kmeans'] = scaler.transform(kmeans.predict(X_train_scaled).reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare scorer, RMSLE - note that np.expm1 is applied since y will be log transformed\n",
    "def rmsle(y, y_pred):\n",
    "    return -np.sqrt(mean_squared_log_error(np.expm1(y), np.expm1(y_pred)))\n",
    "rmsle = make_scorer(rmsle, greater_is_better=False, needs_proba=False, needs_threshold=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to quickly evaluate models\n",
    "def quick_validation(\n",
    "    estimator,\n",
    "    X,\n",
    "    y=np.log1p(train_df.loc[~X_train.index.isin(outlier_ids.index), 'SalePrice']),\n",
    "    scoring=rmsle,\n",
    "):\n",
    "    splitter = ShuffleSplit(n_splits=30, test_size=0.2, random_state=11).split(X)\n",
    "    cv_result = cross_validate(\n",
    "        estimator=estimator,\n",
    "        X=X,\n",
    "        y=y,\n",
    "        scoring=scoring,\n",
    "        n_jobs=12,\n",
    "        cv=splitter,\n",
    "        return_train_score=True,\n",
    "        error_score=-1\n",
    "    )\n",
    "    # print means and decay\n",
    "    print('Train: {:.6f}, Test: {:.6f}, Decay: {:.1%}'.format(\n",
    "        np.mean(cv_result['train_score']),\n",
    "        np.mean(cv_result['test_score']),\n",
    "        np.mean(cv_result['test_score']) / np.mean(cv_result['train_score']) - 1\n",
    "    ))\n",
    "    \n",
    "    return np.mean(cv_result['train_score']), np.mean(cv_result['test_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 0.104480, Test: 0.117491, Decay: 12.5%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.10447958522147462, 0.1174908652704567)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lasso model\n",
    "lasso = Lasso(\n",
    "    alpha=0.001,\n",
    "    tol=1e-6,\n",
    "    random_state=11,\n",
    "    max_iter=2000,\n",
    "    selection='cyclic'\n",
    ")\n",
    "\n",
    "quick_validation(lasso, X_train_scaled.loc[~X_train.index.isin(outlier_ids.index)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 0.102610, Test: 0.120935, Decay: 17.9%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.10260988522380989, 0.12093503255720948)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# linear model\n",
    "lm = LinearRegression(n_jobs=12)\n",
    "\n",
    "quick_validation(lm, X_train_scaled.loc[~X_train.index.isin(outlier_ids.index)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 0.102700, Test: 0.119290, Decay: 16.2%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.10270034227707295, 0.11928986427780698)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ridge\n",
    "ridge = Ridge(tol=1e-7, alpha=5.0, max_iter=1000)\n",
    "\n",
    "quick_validation(ridge, X_train_scaled.loc[~X_train.index.isin(outlier_ids.index)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 0.110462, Test: 0.120605, Decay: 9.2%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.11046152864077179, 0.12060508847699182)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# elasticnet\n",
    "elasticnet = ElasticNet(\n",
    "    alpha=.05,\n",
    "    l1_ratio=0.001,\n",
    "    max_iter=2000,\n",
    "    tol=1e-6,\n",
    "    positive=True,\n",
    "    selection='cyclic',\n",
    "    random_state=11\n",
    ")\n",
    "\n",
    "quick_validation(elasticnet, X_train_scaled.loc[~X_train.index.isin(outlier_ids.index)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 0.102822, Test: 0.127196, Decay: 23.7%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.10282246527906182, 0.1271962243182699)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# gradient boosting\n",
    "gbm = GradientBoostingRegressor(\n",
    "    loss='huber',\n",
    "    learning_rate=0.1,\n",
    "    n_estimators=100,\n",
    "    subsample=0.9,\n",
    "    min_samples_split=0.1,\n",
    "    min_samples_leaf=0.05,\n",
    "    max_depth=3,\n",
    "    random_state=11,\n",
    "    alpha=0.9,\n",
    ")\n",
    "\n",
    "quick_validation(gbm, X_train_scaled.loc[~X_train.index.isin(outlier_ids.index)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 0.120673, Test: 0.128444, Decay: 6.4%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.12067325111848852, 0.12844389360834602)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extreme gbm\n",
    "xgbm = xgb.XGBRegressor(\n",
    "    n_estimators=500,\n",
    "    max_depth=5,\n",
    "    learning_rate=0.5,\n",
    "    verbosity=2,\n",
    "    objective='reg:squaredlogerror',\n",
    "    booster='gblinear',\n",
    "#     tree_method='',\n",
    "    n_jobs=12,\n",
    "    gamma=0.0001,\n",
    "#     min_child_weight=100,\n",
    "#     max_delta_step=50.0,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=1.0,\n",
    "    colsample_bylevel=0.9,\n",
    "    colsample_bynode=0.9,\n",
    "    reg_alpha=0.00001,\n",
    "    reg_lambda=0.001,\n",
    "    random_state=11,\n",
    "    importance='total_gain',\n",
    ")\n",
    "quick_validation(xgbm, X_train.loc[~X_train.index.isin(outlier_ids.index)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's perform hyper-parameter tuning on all models above\n",
    "\n",
    "# prepare scorer, RMSLE - note that np.expm1 is applied since y will be log transformed\n",
    "def rmsle_tuning(y, y_pred):\n",
    "    return np.sqrt(mean_squared_log_error(np.expm1(y), np.expm1(y_pred)))\n",
    "rmsle_tuning = make_scorer(rmsle_tuning, greater_is_better=False, needs_proba=False, needs_threshold=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 30 folds for each of 5 candidates, totalling 150 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=12)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done   1 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=12)]: Done   8 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=12)]: Done  17 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=12)]: Done  37 tasks      | elapsed:    0.9s\n",
      "[Parallel(n_jobs=12)]: Done  48 tasks      | elapsed:    1.2s\n",
      "[Parallel(n_jobs=12)]: Done  61 tasks      | elapsed:    1.4s\n",
      "[Parallel(n_jobs=12)]: Done  74 tasks      | elapsed:    1.7s\n",
      "[Parallel(n_jobs=12)]: Done  89 tasks      | elapsed:    1.9s\n",
      "[Parallel(n_jobs=12)]: Batch computation too fast (0.1977s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=12)]: Done 104 tasks      | elapsed:    1.9s\n",
      "[Parallel(n_jobs=12)]: Done 121 tasks      | elapsed:    2.0s\n",
      "[Parallel(n_jobs=12)]: Done 143 out of 150 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 150 out of 150 | elapsed:    2.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   rank      test     train     decay\n",
      "0     2 -0.117904 -0.103472  0.139483\n",
      "1     1 -0.117491 -0.104480  0.124534\n",
      "2     3 -0.125912 -0.117308  0.073351\n",
      "3     4 -0.211648 -0.204568  0.034607\n",
      "4     5 -0.305630 -0.298276  0.024657\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Lasso(alpha=0.001, max_iter=2000, random_state=11, tol=1e-07)"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = dict(\n",
    "    alpha=[0.0005, 0.001, 0.01, 0.1, 0.2],\n",
    "    tol=[1e-7],\n",
    "    random_state=[11],\n",
    "    selection=['cyclic'],\n",
    "    max_iter=[2000]\n",
    ")\n",
    "\n",
    "lasso = GridSearchCV(\n",
    "    estimator=Lasso(),\n",
    "    param_grid=params,\n",
    "    scoring=rmsle_tuning,\n",
    "    n_jobs=12,\n",
    "    cv=ShuffleSplit(30, test_size=0.2, random_state=11).split(X_train.loc[~X_train.index.isin(outlier_ids.index)]),\n",
    "    verbose=10,\n",
    "    error_score=np.nan,\n",
    "    return_train_score=True\n",
    ")\n",
    "\n",
    "lasso.fit(\n",
    "    X_train_scaled.loc[~X_train.index.isin(outlier_ids.index)],\n",
    "    np.log1p(train_df.loc[~X_train.index.isin(outlier_ids.index), 'SalePrice'])\n",
    ")\n",
    "print(pd.DataFrame({'rank': lasso.cv_results_['rank_test_score'], 'test': lasso.cv_results_['mean_test_score'], 'train': lasso.cv_results_['mean_train_score'],\n",
    "                    'decay': lasso.cv_results_['mean_test_score'] / lasso.cv_results_['mean_train_score'] - 1}))\n",
    "lasso.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 30 folds for each of 9 candidates, totalling 270 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=12)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done   1 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Batch computation too fast (0.0350s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=12)]: Done   8 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done  17 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Batch computation too fast (0.1450s.) Setting batch_size=4.\n",
      "[Parallel(n_jobs=12)]: Done  28 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=12)]: Done  50 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=12)]: Done  72 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=12)]: Batch computation too fast (0.1280s.) Setting batch_size=8.\n",
      "[Parallel(n_jobs=12)]: Done 124 tasks      | elapsed:    0.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   rank      test     train     decay\n",
      "0     9 -0.120936 -0.102609  0.178611\n",
      "1     8 -0.120936 -0.102609  0.178608\n",
      "2     7 -0.120930 -0.102609  0.178550\n",
      "3     6 -0.120872 -0.102609  0.177982\n",
      "4     5 -0.120809 -0.102609  0.177375\n",
      "5     4 -0.120750 -0.102610  0.176790\n",
      "6     3 -0.120693 -0.102610  0.176227\n",
      "7     2 -0.120638 -0.102611  0.175683\n",
      "8     1 -0.120585 -0.102612  0.175158\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=12)]: Done 270 out of 270 | elapsed:    0.5s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Ridge(alpha=0.6, max_iter=2000, random_state=11, tol=1e-07)"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = dict(\n",
    "    alpha=[0.0005, 0.001, 0.01, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6],\n",
    "    tol=[1e-7],\n",
    "    random_state=[11],\n",
    "    max_iter=[2000]\n",
    ")\n",
    "\n",
    "ridge = GridSearchCV(\n",
    "    estimator=Ridge(),\n",
    "    param_grid=params,\n",
    "    scoring=rmsle_tuning,\n",
    "    n_jobs=12,\n",
    "    cv=ShuffleSplit(30, test_size=0.2, random_state=11).split(X_train.loc[~X_train.index.isin(outlier_ids.index)]),\n",
    "    verbose=10,\n",
    "    error_score=np.nan,\n",
    "    return_train_score=True\n",
    ")\n",
    "\n",
    "ridge.fit(\n",
    "    X_train_scaled.loc[~X_train.index.isin(outlier_ids.index)],\n",
    "    np.log1p(train_df.loc[~X_train.index.isin(outlier_ids.index), 'SalePrice'])\n",
    ")\n",
    "print(pd.DataFrame({'rank': ridge.cv_results_['rank_test_score'], 'test': ridge.cv_results_['mean_test_score'], 'train': ridge.cv_results_['mean_train_score'],\n",
    "                    'decay': ridge.cv_results_['mean_test_score'] / ridge.cv_results_['mean_train_score'] - 1}))\n",
    "ridge.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 30 folds for each of 48 candidates, totalling 1440 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=12)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done   1 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=12)]: Done   8 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=12)]: Done  17 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    1.1s\n",
      "[Parallel(n_jobs=12)]: Done  37 tasks      | elapsed:    1.5s\n",
      "[Parallel(n_jobs=12)]: Done  48 tasks      | elapsed:    1.8s\n",
      "[Parallel(n_jobs=12)]: Done  61 tasks      | elapsed:    2.3s\n",
      "[Parallel(n_jobs=12)]: Done  74 tasks      | elapsed:    2.7s\n",
      "[Parallel(n_jobs=12)]: Done  89 tasks      | elapsed:    3.2s\n",
      "[Parallel(n_jobs=12)]: Done 104 tasks      | elapsed:    3.7s\n",
      "[Parallel(n_jobs=12)]: Done 121 tasks      | elapsed:    4.2s\n",
      "[Parallel(n_jobs=12)]: Done 138 tasks      | elapsed:    4.7s\n",
      "[Parallel(n_jobs=12)]: Done 157 tasks      | elapsed:    5.2s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    5.7s\n",
      "[Parallel(n_jobs=12)]: Done 197 tasks      | elapsed:    6.2s\n",
      "[Parallel(n_jobs=12)]: Done 218 tasks      | elapsed:    6.7s\n",
      "[Parallel(n_jobs=12)]: Done 241 tasks      | elapsed:    7.4s\n",
      "[Parallel(n_jobs=12)]: Done 264 tasks      | elapsed:    8.1s\n",
      "[Parallel(n_jobs=12)]: Done 289 tasks      | elapsed:    9.1s\n",
      "[Parallel(n_jobs=12)]: Done 314 tasks      | elapsed:   10.0s\n",
      "[Parallel(n_jobs=12)]: Done 341 tasks      | elapsed:   10.8s\n",
      "[Parallel(n_jobs=12)]: Done 368 tasks      | elapsed:   11.5s\n",
      "[Parallel(n_jobs=12)]: Done 397 tasks      | elapsed:   12.2s\n",
      "[Parallel(n_jobs=12)]: Done 426 tasks      | elapsed:   12.9s\n",
      "[Parallel(n_jobs=12)]: Done 457 tasks      | elapsed:   13.6s\n",
      "[Parallel(n_jobs=12)]: Done 488 tasks      | elapsed:   14.2s\n",
      "[Parallel(n_jobs=12)]: Done 521 tasks      | elapsed:   14.7s\n",
      "[Parallel(n_jobs=12)]: Done 554 tasks      | elapsed:   15.2s\n",
      "[Parallel(n_jobs=12)]: Done 589 tasks      | elapsed:   15.5s\n",
      "[Parallel(n_jobs=12)]: Done 624 tasks      | elapsed:   15.9s\n",
      "[Parallel(n_jobs=12)]: Done 661 tasks      | elapsed:   16.2s\n",
      "[Parallel(n_jobs=12)]: Done 698 tasks      | elapsed:   16.6s\n",
      "[Parallel(n_jobs=12)]: Done 737 tasks      | elapsed:   17.0s\n",
      "[Parallel(n_jobs=12)]: Batch computation too fast (0.1949s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=12)]: Batch computation too fast (0.1920s.) Setting batch_size=4.\n",
      "[Parallel(n_jobs=12)]: Done 784 tasks      | elapsed:   17.3s\n",
      "[Parallel(n_jobs=12)]: Done 916 tasks      | elapsed:   17.8s\n",
      "[Parallel(n_jobs=12)]: Done 1080 tasks      | elapsed:   18.4s\n",
      "[Parallel(n_jobs=12)]: Done 1252 tasks      | elapsed:   19.0s\n",
      "[Parallel(n_jobs=12)]: Done 1440 out of 1440 | elapsed:   19.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    rank      test     train     decay\n",
      "0     24 -0.120567 -0.102612  0.174979\n",
      "1     23 -0.120536 -0.102613  0.174667\n",
      "2     22 -0.120303 -0.102624  0.172280\n",
      "3     19 -0.120038 -0.102645  0.169448\n",
      "4     15 -0.119396 -0.102744  0.162075\n",
      "5     13 -0.118657 -0.102957  0.152482\n",
      "6      7 -0.118197 -0.103206  0.145249\n",
      "7      6 -0.118013 -0.103363  0.141738\n",
      "8     21 -0.120271 -0.102621  0.171993\n",
      "9     20 -0.120216 -0.102623  0.171426\n",
      "10    17 -0.119815 -0.102658  0.167134\n",
      "11    16 -0.119403 -0.102722  0.162382\n",
      "12    12 -0.118546 -0.102975  0.151210\n",
      "13     5 -0.117852 -0.103488  0.138791\n",
      "14     4 -0.117543 -0.104037  0.129826\n",
      "15     2 -0.117495 -0.104315  0.126351\n",
      "16    10 -0.118369 -0.102940  0.149889\n",
      "17     8 -0.118204 -0.103013  0.147469\n",
      "18     3 -0.117509 -0.103766  0.132438\n",
      "19     1 -0.117393 -0.104675  0.121503\n",
      "20    14 -0.118760 -0.107293  0.106877\n",
      "21    26 -0.121028 -0.111245  0.087935\n",
      "22    30 -0.123365 -0.114273  0.079560\n",
      "23    31 -0.124918 -0.116121  0.075762\n",
      "24     9 -0.118283 -0.106203  0.113749\n",
      "25    11 -0.118545 -0.106897  0.108963\n",
      "26    27 -0.121596 -0.112336  0.082428\n",
      "27    32 -0.126206 -0.117949  0.070011\n",
      "28    36 -0.139898 -0.132923  0.052475\n",
      "29    38 -0.164208 -0.157254  0.044224\n",
      "30    40 -0.188156 -0.181165  0.038588\n",
      "31    42 -0.202208 -0.195196  0.035920\n",
      "32    18 -0.119972 -0.109032  0.100342\n",
      "33    25 -0.120668 -0.110282  0.094175\n",
      "34    33 -0.127442 -0.119263  0.068584\n",
      "35    35 -0.136936 -0.129730  0.055544\n",
      "36    39 -0.165605 -0.158792  0.042901\n",
      "37    43 -0.213032 -0.205780  0.035240\n",
      "38    44 -0.263033 -0.255824  0.028179\n",
      "39    46 -0.289079 -0.281875  0.025560\n",
      "40    28 -0.121802 -0.111530  0.092093\n",
      "41    29 -0.122955 -0.113291  0.085297\n",
      "42    34 -0.133971 -0.126229  0.061330\n",
      "43    37 -0.147778 -0.140896  0.048843\n",
      "44    41 -0.191205 -0.184277  0.037596\n",
      "45    45 -0.265605 -0.258069  0.029203\n",
      "46    47 -0.331312 -0.323705  0.023501\n",
      "47    48 -0.364366 -0.356702  0.021486\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ElasticNet(alpha=0.01, l1_ratio=0.1, max_iter=2000, random_state=11, tol=1e-07)"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = dict(\n",
    "    alpha=[0.0005, 0.001, 0.01, 0.1, 0.2, 0.3],\n",
    "    l1_ratio=[0.005, 0.01, 0.05, 0.1, 0.25, 0.5, 0.75, 0.9],\n",
    "    tol=[1e-7],\n",
    "    random_state=[11],\n",
    "    max_iter=[2000],\n",
    "    selection=['cyclic']\n",
    ")\n",
    "\n",
    "elasticnet = GridSearchCV(\n",
    "    estimator=ElasticNet(),\n",
    "    param_grid=params,\n",
    "    scoring=rmsle_tuning,\n",
    "    n_jobs=12,\n",
    "    cv=ShuffleSplit(30, test_size=0.2, random_state=11).split(X_train.loc[~X_train.index.isin(outlier_ids.index)]),\n",
    "    verbose=10,\n",
    "    error_score=np.nan,\n",
    "    return_train_score=True\n",
    ")\n",
    "\n",
    "elasticnet.fit(\n",
    "    X_train_scaled.loc[~X_train.index.isin(outlier_ids.index)],\n",
    "    np.log1p(train_df.loc[~X_train.index.isin(outlier_ids.index), 'SalePrice'])\n",
    ")\n",
    "print(pd.DataFrame({\n",
    "    'rank': elasticnet.cv_results_['rank_test_score'], \n",
    "    'test': elasticnet.cv_results_['mean_test_score'], \n",
    "    'train': elasticnet.cv_results_['mean_train_score'],\n",
    "    'decay': elasticnet.cv_results_['mean_test_score'] / elasticnet.cv_results_['mean_train_score'] - 1})).sort_values('rank').iloc[:20]\n",
    "elasticnet.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 10368 candidates, totalling 103680 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=12)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done   1 tasks      | elapsed:    1.9s\n",
      "[Parallel(n_jobs=12)]: Done   8 tasks      | elapsed:    2.0s\n",
      "[Parallel(n_jobs=12)]: Done  17 tasks      | elapsed:    2.1s\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    2.2s\n",
      "[Parallel(n_jobs=12)]: Done  37 tasks      | elapsed:    2.4s\n",
      "[Parallel(n_jobs=12)]: Done  48 tasks      | elapsed:    2.5s\n",
      "[Parallel(n_jobs=12)]: Done  61 tasks      | elapsed:    2.6s\n",
      "[Parallel(n_jobs=12)]: Done  74 tasks      | elapsed:    2.8s\n",
      "[Parallel(n_jobs=12)]: Done  89 tasks      | elapsed:    3.0s\n",
      "[Parallel(n_jobs=12)]: Done 104 tasks      | elapsed:    3.2s\n",
      "[Parallel(n_jobs=12)]: Done 121 tasks      | elapsed:    3.4s\n",
      "[Parallel(n_jobs=12)]: Done 138 tasks      | elapsed:    3.6s\n",
      "[Parallel(n_jobs=12)]: Done 157 tasks      | elapsed:    3.8s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    4.1s\n",
      "[Parallel(n_jobs=12)]: Done 197 tasks      | elapsed:    4.3s\n",
      "[Parallel(n_jobs=12)]: Done 218 tasks      | elapsed:    4.6s\n",
      "[Parallel(n_jobs=12)]: Done 241 tasks      | elapsed:    4.8s\n",
      "[Parallel(n_jobs=12)]: Done 264 tasks      | elapsed:    5.1s\n",
      "[Parallel(n_jobs=12)]: Done 289 tasks      | elapsed:    5.4s\n",
      "[Parallel(n_jobs=12)]: Done 314 tasks      | elapsed:    5.7s\n",
      "[Parallel(n_jobs=12)]: Done 341 tasks      | elapsed:    6.1s\n",
      "[Parallel(n_jobs=12)]: Done 368 tasks      | elapsed:    6.4s\n",
      "[Parallel(n_jobs=12)]: Done 397 tasks      | elapsed:    6.8s\n",
      "[Parallel(n_jobs=12)]: Done 426 tasks      | elapsed:    7.1s\n",
      "[Parallel(n_jobs=12)]: Done 457 tasks      | elapsed:    7.5s\n",
      "[Parallel(n_jobs=12)]: Done 488 tasks      | elapsed:    7.8s\n",
      "[Parallel(n_jobs=12)]: Done 521 tasks      | elapsed:    8.3s\n",
      "[Parallel(n_jobs=12)]: Done 554 tasks      | elapsed:    8.6s\n",
      "[Parallel(n_jobs=12)]: Done 589 tasks      | elapsed:    9.0s\n",
      "[Parallel(n_jobs=12)]: Done 624 tasks      | elapsed:    9.4s\n",
      "[Parallel(n_jobs=12)]: Done 661 tasks      | elapsed:    9.9s\n",
      "[Parallel(n_jobs=12)]: Done 698 tasks      | elapsed:   10.3s\n",
      "[Parallel(n_jobs=12)]: Done 737 tasks      | elapsed:   10.7s\n",
      "[Parallel(n_jobs=12)]: Done 776 tasks      | elapsed:   11.2s\n",
      "[Parallel(n_jobs=12)]: Done 817 tasks      | elapsed:   11.6s\n",
      "[Parallel(n_jobs=12)]: Done 858 tasks      | elapsed:   12.1s\n",
      "[Parallel(n_jobs=12)]: Done 901 tasks      | elapsed:   12.6s\n",
      "[Parallel(n_jobs=12)]: Done 944 tasks      | elapsed:   13.1s\n",
      "[Parallel(n_jobs=12)]: Done 989 tasks      | elapsed:   13.6s\n",
      "[Parallel(n_jobs=12)]: Done 1034 tasks      | elapsed:   14.1s\n",
      "[Parallel(n_jobs=12)]: Done 1081 tasks      | elapsed:   14.7s\n",
      "[Parallel(n_jobs=12)]: Done 1128 tasks      | elapsed:   15.2s\n",
      "[Parallel(n_jobs=12)]: Done 1177 tasks      | elapsed:   15.9s\n",
      "[Parallel(n_jobs=12)]: Done 1226 tasks      | elapsed:   16.5s\n",
      "[Parallel(n_jobs=12)]: Done 1277 tasks      | elapsed:   17.1s\n",
      "[Parallel(n_jobs=12)]: Done 1328 tasks      | elapsed:   17.8s\n",
      "[Parallel(n_jobs=12)]: Done 1381 tasks      | elapsed:   18.5s\n",
      "[Parallel(n_jobs=12)]: Done 1434 tasks      | elapsed:   19.2s\n",
      "[Parallel(n_jobs=12)]: Done 1489 tasks      | elapsed:   19.9s\n",
      "[Parallel(n_jobs=12)]: Done 1544 tasks      | elapsed:   20.7s\n",
      "[Parallel(n_jobs=12)]: Done 1601 tasks      | elapsed:   21.4s\n",
      "[Parallel(n_jobs=12)]: Done 1658 tasks      | elapsed:   22.1s\n",
      "[Parallel(n_jobs=12)]: Done 1717 tasks      | elapsed:   22.7s\n",
      "[Parallel(n_jobs=12)]: Done 1776 tasks      | elapsed:   23.4s\n",
      "[Parallel(n_jobs=12)]: Done 1837 tasks      | elapsed:   24.1s\n",
      "[Parallel(n_jobs=12)]: Done 1898 tasks      | elapsed:   24.8s\n",
      "[Parallel(n_jobs=12)]: Done 1961 tasks      | elapsed:   25.6s\n",
      "[Parallel(n_jobs=12)]: Done 2024 tasks      | elapsed:   26.2s\n",
      "[Parallel(n_jobs=12)]: Done 2089 tasks      | elapsed:   27.0s\n",
      "[Parallel(n_jobs=12)]: Done 2154 tasks      | elapsed:   27.7s\n",
      "[Parallel(n_jobs=12)]: Done 2221 tasks      | elapsed:   29.8s\n",
      "[Parallel(n_jobs=12)]: Done 2288 tasks      | elapsed:   31.7s\n",
      "[Parallel(n_jobs=12)]: Done 2357 tasks      | elapsed:   33.8s\n",
      "[Parallel(n_jobs=12)]: Done 2426 tasks      | elapsed:   36.0s\n",
      "[Parallel(n_jobs=12)]: Done 2497 tasks      | elapsed:   38.3s\n",
      "[Parallel(n_jobs=12)]: Done 2568 tasks      | elapsed:   40.6s\n",
      "[Parallel(n_jobs=12)]: Done 2641 tasks      | elapsed:   42.9s\n",
      "[Parallel(n_jobs=12)]: Done 2714 tasks      | elapsed:   45.1s\n",
      "[Parallel(n_jobs=12)]: Done 2789 tasks      | elapsed:   47.5s\n",
      "[Parallel(n_jobs=12)]: Done 2864 tasks      | elapsed:   49.9s\n",
      "[Parallel(n_jobs=12)]: Done 2941 tasks      | elapsed:   52.3s\n",
      "[Parallel(n_jobs=12)]: Done 3018 tasks      | elapsed:   54.8s\n",
      "[Parallel(n_jobs=12)]: Done 3097 tasks      | elapsed:   57.2s\n",
      "[Parallel(n_jobs=12)]: Done 3176 tasks      | elapsed:   59.7s\n",
      "[Parallel(n_jobs=12)]: Done 3257 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=12)]: Done 3338 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=12)]: Done 3421 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=12)]: Done 3504 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=12)]: Done 3589 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=12)]: Done 3674 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=12)]: Done 3761 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=12)]: Done 3848 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=12)]: Done 3937 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=12)]: Done 4026 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=12)]: Done 4117 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=12)]: Done 4208 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=12)]: Done 4301 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=12)]: Done 4394 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=12)]: Done 4489 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=12)]: Done 4584 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=12)]: Done 4681 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=12)]: Done 4778 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=12)]: Done 4877 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=12)]: Done 4976 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=12)]: Done 5077 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=12)]: Done 5178 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=12)]: Done 5281 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=12)]: Done 5384 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=12)]: Done 5489 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=12)]: Done 5594 tasks      | elapsed:  2.0min\n",
      "[Parallel(n_jobs=12)]: Done 5701 tasks      | elapsed:  2.0min\n",
      "[Parallel(n_jobs=12)]: Done 5808 tasks      | elapsed:  2.0min\n",
      "[Parallel(n_jobs=12)]: Done 5917 tasks      | elapsed:  2.1min\n",
      "[Parallel(n_jobs=12)]: Done 6026 tasks      | elapsed:  2.1min\n",
      "[Parallel(n_jobs=12)]: Done 6137 tasks      | elapsed:  2.1min\n",
      "[Parallel(n_jobs=12)]: Done 6248 tasks      | elapsed:  2.2min\n",
      "[Parallel(n_jobs=12)]: Done 6361 tasks      | elapsed:  2.2min\n",
      "[Parallel(n_jobs=12)]: Done 6474 tasks      | elapsed:  2.2min\n",
      "[Parallel(n_jobs=12)]: Done 6589 tasks      | elapsed:  2.3min\n",
      "[Parallel(n_jobs=12)]: Done 6704 tasks      | elapsed:  2.3min\n",
      "[Parallel(n_jobs=12)]: Done 6821 tasks      | elapsed:  2.4min\n",
      "[Parallel(n_jobs=12)]: Done 6938 tasks      | elapsed:  2.4min\n",
      "[Parallel(n_jobs=12)]: Done 7057 tasks      | elapsed:  2.5min\n",
      "[Parallel(n_jobs=12)]: Done 7176 tasks      | elapsed:  2.5min\n",
      "[Parallel(n_jobs=12)]: Done 7297 tasks      | elapsed:  2.6min\n",
      "[Parallel(n_jobs=12)]: Done 7418 tasks      | elapsed:  2.6min\n",
      "[Parallel(n_jobs=12)]: Done 7541 tasks      | elapsed:  2.7min\n",
      "[Parallel(n_jobs=12)]: Done 7664 tasks      | elapsed:  2.8min\n",
      "[Parallel(n_jobs=12)]: Done 7789 tasks      | elapsed:  2.8min\n",
      "[Parallel(n_jobs=12)]: Done 7914 tasks      | elapsed:  2.9min\n",
      "[Parallel(n_jobs=12)]: Done 8041 tasks      | elapsed:  2.9min\n",
      "[Parallel(n_jobs=12)]: Done 8168 tasks      | elapsed:  3.0min\n",
      "[Parallel(n_jobs=12)]: Done 8297 tasks      | elapsed:  3.1min\n",
      "[Parallel(n_jobs=12)]: Done 8426 tasks      | elapsed:  3.1min\n",
      "[Parallel(n_jobs=12)]: Done 8557 tasks      | elapsed:  3.2min\n",
      "[Parallel(n_jobs=12)]: Batch computation too fast (0.1983s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=12)]: Done 8688 tasks      | elapsed:  3.2min\n",
      "[Parallel(n_jobs=12)]: Done 8930 tasks      | elapsed:  3.3min\n",
      "[Parallel(n_jobs=12)]: Done 9196 tasks      | elapsed:  3.3min\n",
      "[Parallel(n_jobs=12)]: Done 9466 tasks      | elapsed:  3.3min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=12)]: Done 9736 tasks      | elapsed:  3.4min\n",
      "[Parallel(n_jobs=12)]: Done 10010 tasks      | elapsed:  3.4min\n",
      "[Parallel(n_jobs=12)]: Done 10284 tasks      | elapsed:  3.4min\n",
      "[Parallel(n_jobs=12)]: Done 10562 tasks      | elapsed:  3.5min\n",
      "[Parallel(n_jobs=12)]: Done 10840 tasks      | elapsed:  3.5min\n",
      "[Parallel(n_jobs=12)]: Done 11122 tasks      | elapsed:  3.6min\n",
      "[Parallel(n_jobs=12)]: Done 11404 tasks      | elapsed:  3.7min\n",
      "[Parallel(n_jobs=12)]: Done 11690 tasks      | elapsed:  3.8min\n",
      "[Parallel(n_jobs=12)]: Done 11976 tasks      | elapsed:  3.9min\n",
      "[Parallel(n_jobs=12)]: Done 12266 tasks      | elapsed:  4.0min\n",
      "[Parallel(n_jobs=12)]: Done 12556 tasks      | elapsed:  4.1min\n",
      "[Parallel(n_jobs=12)]: Done 12850 tasks      | elapsed:  4.2min\n",
      "[Parallel(n_jobs=12)]: Done 13144 tasks      | elapsed:  4.3min\n",
      "[Parallel(n_jobs=12)]: Done 13442 tasks      | elapsed:  4.3min\n",
      "[Parallel(n_jobs=12)]: Done 13740 tasks      | elapsed:  4.4min\n",
      "[Parallel(n_jobs=12)]: Done 14042 tasks      | elapsed:  4.4min\n",
      "[Parallel(n_jobs=12)]: Done 14344 tasks      | elapsed:  4.5min\n",
      "[Parallel(n_jobs=12)]: Done 14650 tasks      | elapsed:  4.6min\n",
      "[Parallel(n_jobs=12)]: Done 14956 tasks      | elapsed:  4.6min\n",
      "[Parallel(n_jobs=12)]: Done 15266 tasks      | elapsed:  4.7min\n",
      "[Parallel(n_jobs=12)]: Done 15576 tasks      | elapsed:  4.8min\n",
      "[Parallel(n_jobs=12)]: Done 15890 tasks      | elapsed:  4.8min\n",
      "[Parallel(n_jobs=12)]: Done 16204 tasks      | elapsed:  4.9min\n",
      "[Parallel(n_jobs=12)]: Done 16522 tasks      | elapsed:  5.0min\n",
      "[Parallel(n_jobs=12)]: Done 16840 tasks      | elapsed:  5.0min\n",
      "[Parallel(n_jobs=12)]: Done 17162 tasks      | elapsed:  5.1min\n",
      "[Parallel(n_jobs=12)]: Done 17484 tasks      | elapsed:  5.2min\n",
      "[Parallel(n_jobs=12)]: Done 17810 tasks      | elapsed:  5.2min\n",
      "[Parallel(n_jobs=12)]: Done 18136 tasks      | elapsed:  5.2min\n",
      "[Parallel(n_jobs=12)]: Done 18466 tasks      | elapsed:  5.2min\n",
      "[Parallel(n_jobs=12)]: Done 18796 tasks      | elapsed:  5.3min\n",
      "[Parallel(n_jobs=12)]: Done 19130 tasks      | elapsed:  5.3min\n",
      "[Parallel(n_jobs=12)]: Done 19464 tasks      | elapsed:  5.3min\n",
      "[Parallel(n_jobs=12)]: Done 19802 tasks      | elapsed:  5.4min\n",
      "[Parallel(n_jobs=12)]: Done 20140 tasks      | elapsed:  5.5min\n",
      "[Parallel(n_jobs=12)]: Done 20482 tasks      | elapsed:  5.5min\n",
      "[Parallel(n_jobs=12)]: Done 20824 tasks      | elapsed:  5.6min\n",
      "[Parallel(n_jobs=12)]: Done 21170 tasks      | elapsed:  5.7min\n",
      "[Parallel(n_jobs=12)]: Done 21516 tasks      | elapsed:  5.8min\n",
      "[Parallel(n_jobs=12)]: Done 21866 tasks      | elapsed:  5.8min\n",
      "[Parallel(n_jobs=12)]: Done 22216 tasks      | elapsed:  5.9min\n",
      "[Parallel(n_jobs=12)]: Done 22570 tasks      | elapsed:  5.9min\n",
      "[Parallel(n_jobs=12)]: Done 22924 tasks      | elapsed:  6.0min\n",
      "[Parallel(n_jobs=12)]: Done 23282 tasks      | elapsed:  6.0min\n",
      "[Parallel(n_jobs=12)]: Done 23640 tasks      | elapsed:  6.0min\n",
      "[Parallel(n_jobs=12)]: Done 24002 tasks      | elapsed:  6.1min\n",
      "[Parallel(n_jobs=12)]: Done 24364 tasks      | elapsed:  6.1min\n",
      "[Parallel(n_jobs=12)]: Done 24730 tasks      | elapsed:  6.2min\n",
      "[Parallel(n_jobs=12)]: Done 25096 tasks      | elapsed:  6.2min\n",
      "[Parallel(n_jobs=12)]: Done 25466 tasks      | elapsed:  6.2min\n",
      "[Parallel(n_jobs=12)]: Done 25836 tasks      | elapsed:  6.3min\n",
      "[Parallel(n_jobs=12)]: Done 26210 tasks      | elapsed:  6.3min\n",
      "[Parallel(n_jobs=12)]: Done 26584 tasks      | elapsed:  6.4min\n",
      "[Parallel(n_jobs=12)]: Done 26962 tasks      | elapsed:  6.4min\n",
      "[Parallel(n_jobs=12)]: Done 27340 tasks      | elapsed:  6.4min\n",
      "[Parallel(n_jobs=12)]: Done 27722 tasks      | elapsed:  6.5min\n",
      "[Parallel(n_jobs=12)]: Done 28104 tasks      | elapsed:  6.5min\n",
      "[Parallel(n_jobs=12)]: Done 28490 tasks      | elapsed:  6.5min\n",
      "[Parallel(n_jobs=12)]: Done 28876 tasks      | elapsed:  6.6min\n",
      "[Parallel(n_jobs=12)]: Done 29266 tasks      | elapsed:  6.6min\n",
      "[Parallel(n_jobs=12)]: Done 29656 tasks      | elapsed:  6.7min\n",
      "[Parallel(n_jobs=12)]: Done 30050 tasks      | elapsed:  6.7min\n",
      "[Parallel(n_jobs=12)]: Done 30444 tasks      | elapsed:  6.8min\n",
      "[Parallel(n_jobs=12)]: Done 30842 tasks      | elapsed:  6.8min\n",
      "[Parallel(n_jobs=12)]: Done 31240 tasks      | elapsed:  6.9min\n",
      "[Parallel(n_jobs=12)]: Done 31642 tasks      | elapsed:  6.9min\n",
      "[Parallel(n_jobs=12)]: Done 32044 tasks      | elapsed:  7.0min\n",
      "[Parallel(n_jobs=12)]: Done 32450 tasks      | elapsed:  7.0min\n",
      "[Parallel(n_jobs=12)]: Done 32856 tasks      | elapsed:  7.1min\n",
      "[Parallel(n_jobs=12)]: Done 33266 tasks      | elapsed:  7.1min\n",
      "[Parallel(n_jobs=12)]: Done 33676 tasks      | elapsed:  7.2min\n",
      "[Parallel(n_jobs=12)]: Done 34090 tasks      | elapsed:  7.2min\n",
      "[Parallel(n_jobs=12)]: Done 34504 tasks      | elapsed:  7.3min\n",
      "[Parallel(n_jobs=12)]: Done 34922 tasks      | elapsed:  7.4min\n",
      "[Parallel(n_jobs=12)]: Done 35340 tasks      | elapsed:  7.4min\n",
      "[Parallel(n_jobs=12)]: Done 35762 tasks      | elapsed:  7.5min\n",
      "[Parallel(n_jobs=12)]: Done 36184 tasks      | elapsed:  7.6min\n",
      "[Parallel(n_jobs=12)]: Done 36610 tasks      | elapsed:  7.7min\n",
      "[Parallel(n_jobs=12)]: Done 37036 tasks      | elapsed:  7.9min\n",
      "[Parallel(n_jobs=12)]: Done 37466 tasks      | elapsed:  8.1min\n",
      "[Parallel(n_jobs=12)]: Done 37896 tasks      | elapsed:  8.3min\n",
      "[Parallel(n_jobs=12)]: Done 38330 tasks      | elapsed:  8.6min\n",
      "[Parallel(n_jobs=12)]: Done 38764 tasks      | elapsed:  8.8min\n",
      "[Parallel(n_jobs=12)]: Done 39202 tasks      | elapsed:  9.0min\n",
      "[Parallel(n_jobs=12)]: Done 39640 tasks      | elapsed:  9.2min\n",
      "[Parallel(n_jobs=12)]: Done 40082 tasks      | elapsed:  9.3min\n",
      "[Parallel(n_jobs=12)]: Done 40524 tasks      | elapsed:  9.5min\n",
      "[Parallel(n_jobs=12)]: Done 40970 tasks      | elapsed:  9.7min\n",
      "[Parallel(n_jobs=12)]: Done 41416 tasks      | elapsed:  9.9min\n",
      "[Parallel(n_jobs=12)]: Done 41866 tasks      | elapsed: 10.0min\n",
      "[Parallel(n_jobs=12)]: Done 42316 tasks      | elapsed: 10.2min\n",
      "[Parallel(n_jobs=12)]: Done 42770 tasks      | elapsed: 10.4min\n",
      "[Parallel(n_jobs=12)]: Done 43224 tasks      | elapsed: 10.6min\n",
      "[Parallel(n_jobs=12)]: Done 43682 tasks      | elapsed: 10.7min\n",
      "[Parallel(n_jobs=12)]: Done 44140 tasks      | elapsed: 10.7min\n",
      "[Parallel(n_jobs=12)]: Done 44602 tasks      | elapsed: 10.8min\n",
      "[Parallel(n_jobs=12)]: Done 45064 tasks      | elapsed: 10.9min\n",
      "[Parallel(n_jobs=12)]: Done 45530 tasks      | elapsed: 11.0min\n",
      "[Parallel(n_jobs=12)]: Done 45996 tasks      | elapsed: 11.1min\n",
      "[Parallel(n_jobs=12)]: Done 46466 tasks      | elapsed: 11.2min\n",
      "[Parallel(n_jobs=12)]: Done 46936 tasks      | elapsed: 11.4min\n",
      "[Parallel(n_jobs=12)]: Done 47410 tasks      | elapsed: 11.6min\n",
      "[Parallel(n_jobs=12)]: Done 47884 tasks      | elapsed: 11.7min\n",
      "[Parallel(n_jobs=12)]: Done 48362 tasks      | elapsed: 11.8min\n",
      "[Parallel(n_jobs=12)]: Done 48840 tasks      | elapsed: 12.0min\n",
      "[Parallel(n_jobs=12)]: Done 49322 tasks      | elapsed: 12.1min\n",
      "[Parallel(n_jobs=12)]: Done 49804 tasks      | elapsed: 12.3min\n",
      "[Parallel(n_jobs=12)]: Done 50290 tasks      | elapsed: 12.4min\n",
      "[Parallel(n_jobs=12)]: Done 50776 tasks      | elapsed: 12.5min\n",
      "[Parallel(n_jobs=12)]: Done 51266 tasks      | elapsed: 12.6min\n",
      "[Parallel(n_jobs=12)]: Done 51756 tasks      | elapsed: 12.7min\n",
      "[Parallel(n_jobs=12)]: Done 52250 tasks      | elapsed: 12.7min\n",
      "[Parallel(n_jobs=12)]: Done 52744 tasks      | elapsed: 12.8min\n",
      "[Parallel(n_jobs=12)]: Done 53242 tasks      | elapsed: 12.8min\n",
      "[Parallel(n_jobs=12)]: Done 53740 tasks      | elapsed: 12.9min\n",
      "[Parallel(n_jobs=12)]: Done 54242 tasks      | elapsed: 12.9min\n",
      "[Parallel(n_jobs=12)]: Done 54744 tasks      | elapsed: 13.1min\n",
      "[Parallel(n_jobs=12)]: Done 55250 tasks      | elapsed: 13.2min\n",
      "[Parallel(n_jobs=12)]: Done 55756 tasks      | elapsed: 13.3min\n",
      "[Parallel(n_jobs=12)]: Done 56266 tasks      | elapsed: 13.4min\n",
      "[Parallel(n_jobs=12)]: Done 56776 tasks      | elapsed: 13.4min\n",
      "[Parallel(n_jobs=12)]: Done 57290 tasks      | elapsed: 13.5min\n",
      "[Parallel(n_jobs=12)]: Done 57804 tasks      | elapsed: 13.6min\n",
      "[Parallel(n_jobs=12)]: Done 58322 tasks      | elapsed: 13.6min\n",
      "[Parallel(n_jobs=12)]: Done 58840 tasks      | elapsed: 13.7min\n",
      "[Parallel(n_jobs=12)]: Done 59362 tasks      | elapsed: 13.7min\n",
      "[Parallel(n_jobs=12)]: Done 59884 tasks      | elapsed: 13.8min\n",
      "[Parallel(n_jobs=12)]: Done 60410 tasks      | elapsed: 13.9min\n",
      "[Parallel(n_jobs=12)]: Done 60936 tasks      | elapsed: 13.9min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=12)]: Done 61466 tasks      | elapsed: 14.0min\n",
      "[Parallel(n_jobs=12)]: Done 61996 tasks      | elapsed: 14.0min\n",
      "[Parallel(n_jobs=12)]: Done 62530 tasks      | elapsed: 14.1min\n",
      "[Parallel(n_jobs=12)]: Done 63064 tasks      | elapsed: 14.1min\n",
      "[Parallel(n_jobs=12)]: Done 63602 tasks      | elapsed: 14.2min\n",
      "[Parallel(n_jobs=12)]: Done 64140 tasks      | elapsed: 14.3min\n",
      "[Parallel(n_jobs=12)]: Done 64682 tasks      | elapsed: 14.3min\n",
      "[Parallel(n_jobs=12)]: Done 65224 tasks      | elapsed: 14.4min\n",
      "[Parallel(n_jobs=12)]: Done 65770 tasks      | elapsed: 14.5min\n",
      "[Parallel(n_jobs=12)]: Done 66316 tasks      | elapsed: 14.5min\n",
      "[Parallel(n_jobs=12)]: Done 66866 tasks      | elapsed: 14.6min\n",
      "[Parallel(n_jobs=12)]: Done 67416 tasks      | elapsed: 14.7min\n",
      "[Parallel(n_jobs=12)]: Done 67970 tasks      | elapsed: 14.7min\n",
      "[Parallel(n_jobs=12)]: Done 68524 tasks      | elapsed: 14.8min\n",
      "[Parallel(n_jobs=12)]: Done 69082 tasks      | elapsed: 14.8min\n",
      "[Parallel(n_jobs=12)]: Done 69640 tasks      | elapsed: 15.0min\n",
      "[Parallel(n_jobs=12)]: Done 70202 tasks      | elapsed: 15.1min\n",
      "[Parallel(n_jobs=12)]: Done 70764 tasks      | elapsed: 15.2min\n",
      "[Parallel(n_jobs=12)]: Done 71330 tasks      | elapsed: 15.3min\n",
      "[Parallel(n_jobs=12)]: Done 71896 tasks      | elapsed: 15.6min\n",
      "[Parallel(n_jobs=12)]: Done 72466 tasks      | elapsed: 15.9min\n",
      "[Parallel(n_jobs=12)]: Done 73036 tasks      | elapsed: 16.2min\n",
      "[Parallel(n_jobs=12)]: Done 73610 tasks      | elapsed: 16.5min\n",
      "[Parallel(n_jobs=12)]: Done 74184 tasks      | elapsed: 16.7min\n",
      "[Parallel(n_jobs=12)]: Done 74762 tasks      | elapsed: 17.0min\n",
      "[Parallel(n_jobs=12)]: Done 75340 tasks      | elapsed: 17.2min\n",
      "[Parallel(n_jobs=12)]: Done 75922 tasks      | elapsed: 17.4min\n",
      "[Parallel(n_jobs=12)]: Done 76504 tasks      | elapsed: 17.5min\n",
      "[Parallel(n_jobs=12)]: Done 77090 tasks      | elapsed: 17.7min\n",
      "[Parallel(n_jobs=12)]: Done 77676 tasks      | elapsed: 17.8min\n",
      "[Parallel(n_jobs=12)]: Done 78266 tasks      | elapsed: 17.9min\n",
      "[Parallel(n_jobs=12)]: Done 78856 tasks      | elapsed: 18.0min\n",
      "[Parallel(n_jobs=12)]: Done 79450 tasks      | elapsed: 18.1min\n",
      "[Parallel(n_jobs=12)]: Done 80044 tasks      | elapsed: 18.2min\n",
      "[Parallel(n_jobs=12)]: Done 80642 tasks      | elapsed: 18.3min\n",
      "[Parallel(n_jobs=12)]: Done 81240 tasks      | elapsed: 18.5min\n",
      "[Parallel(n_jobs=12)]: Done 81842 tasks      | elapsed: 18.7min\n",
      "[Parallel(n_jobs=12)]: Done 82444 tasks      | elapsed: 18.9min\n",
      "[Parallel(n_jobs=12)]: Done 83050 tasks      | elapsed: 19.1min\n",
      "[Parallel(n_jobs=12)]: Done 83656 tasks      | elapsed: 19.2min\n",
      "[Parallel(n_jobs=12)]: Done 84266 tasks      | elapsed: 19.4min\n",
      "[Parallel(n_jobs=12)]: Done 84876 tasks      | elapsed: 19.5min\n",
      "[Parallel(n_jobs=12)]: Done 85490 tasks      | elapsed: 19.6min\n",
      "[Parallel(n_jobs=12)]: Done 86104 tasks      | elapsed: 19.7min\n",
      "[Parallel(n_jobs=12)]: Done 86722 tasks      | elapsed: 19.8min\n",
      "[Parallel(n_jobs=12)]: Done 87340 tasks      | elapsed: 19.8min\n",
      "[Parallel(n_jobs=12)]: Done 87962 tasks      | elapsed: 19.9min\n",
      "[Parallel(n_jobs=12)]: Done 88584 tasks      | elapsed: 19.9min\n",
      "[Parallel(n_jobs=12)]: Done 89210 tasks      | elapsed: 20.1min\n",
      "[Parallel(n_jobs=12)]: Done 89836 tasks      | elapsed: 20.2min\n",
      "[Parallel(n_jobs=12)]: Done 90466 tasks      | elapsed: 20.3min\n",
      "[Parallel(n_jobs=12)]: Done 91096 tasks      | elapsed: 20.4min\n",
      "[Parallel(n_jobs=12)]: Done 91730 tasks      | elapsed: 20.5min\n",
      "[Parallel(n_jobs=12)]: Done 92364 tasks      | elapsed: 20.6min\n",
      "[Parallel(n_jobs=12)]: Done 93002 tasks      | elapsed: 20.7min\n",
      "[Parallel(n_jobs=12)]: Done 93640 tasks      | elapsed: 20.8min\n",
      "[Parallel(n_jobs=12)]: Done 94282 tasks      | elapsed: 20.8min\n",
      "[Parallel(n_jobs=12)]: Done 94924 tasks      | elapsed: 20.9min\n",
      "[Parallel(n_jobs=12)]: Done 95570 tasks      | elapsed: 20.9min\n",
      "[Parallel(n_jobs=12)]: Done 96216 tasks      | elapsed: 21.0min\n",
      "[Parallel(n_jobs=12)]: Done 96866 tasks      | elapsed: 21.1min\n",
      "[Parallel(n_jobs=12)]: Done 97516 tasks      | elapsed: 21.1min\n",
      "[Parallel(n_jobs=12)]: Done 98170 tasks      | elapsed: 21.2min\n",
      "[Parallel(n_jobs=12)]: Done 98824 tasks      | elapsed: 21.3min\n",
      "[Parallel(n_jobs=12)]: Done 99482 tasks      | elapsed: 21.4min\n",
      "[Parallel(n_jobs=12)]: Done 100140 tasks      | elapsed: 21.5min\n",
      "[Parallel(n_jobs=12)]: Done 100802 tasks      | elapsed: 21.5min\n",
      "[Parallel(n_jobs=12)]: Done 101464 tasks      | elapsed: 21.6min\n",
      "[Parallel(n_jobs=12)]: Done 102130 tasks      | elapsed: 21.7min\n",
      "[Parallel(n_jobs=12)]: Done 102796 tasks      | elapsed: 21.8min\n",
      "[Parallel(n_jobs=12)]: Done 103466 tasks      | elapsed: 21.8min\n",
      "[Parallel(n_jobs=12)]: Done 103680 out of 103680 | elapsed: 21.9min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        rank      test     train     decay\n",
      "0        265 -0.129954 -0.109072  0.191446\n",
      "1         49 -0.128003 -0.103480  0.236985\n",
      "2         34 -0.127742 -0.102145  0.250588\n",
      "3        153 -0.128812 -0.105621  0.219574\n",
      "4         74 -0.128179 -0.101190  0.266716\n",
      "...      ...       ...       ...       ...\n",
      "10363  10225 -1.051762 -1.062995 -0.010567\n",
      "10364  10153 -1.043500 -1.054650 -0.010572\n",
      "10365  10009 -1.041056 -1.052126 -0.010522\n",
      "10366  10225 -1.051762 -1.062995 -0.010567\n",
      "10367  10153 -1.043500 -1.054650 -0.010572\n",
      "\n",
      "[10368 rows x 4 columns]\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'sort_values'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-151-f98d2c12c30f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     32\u001b[0m     \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog1p\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m~\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutlier_ids\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'SalePrice'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m )\n\u001b[1;32m---> 34\u001b[1;33m print(pd.DataFrame({\n\u001b[0m\u001b[0;32m     35\u001b[0m     \u001b[1;34m'rank'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mgbm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcv_results_\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'rank_test_score'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m     \u001b[1;34m'test'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mgbm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcv_results_\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'mean_test_score'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'sort_values'"
     ]
    }
   ],
   "source": [
    "params = dict(\n",
    "    loss=['ls', 'lad', 'huber', 'quantile'],\n",
    "    learning_rate=[0.1, 0.5],\n",
    "    n_estimators=[200],\n",
    "    subsample=[0.5, 0.75, 0.9],\n",
    "    min_samples_split=[0.1, 0.05],\n",
    "    min_samples_leaf=[0.01, 0.02, 0.03],\n",
    "    max_depth=[3, 4],\n",
    "    random_state=[11],\n",
    "    max_features=['sqrt', 'log2'],\n",
    "    alpha=[0.1, 0.9, 0.99],\n",
    "    max_leaf_nodes=[None, 10, 20],\n",
    "    validation_fraction=[0.1],\n",
    "    n_iter_no_change=[25],\n",
    "    tol=[1e-3],\n",
    "    ccp_alpha=[0.0, 0.2]\n",
    ")\n",
    "\n",
    "gbm = GridSearchCV(\n",
    "    estimator=GradientBoostingRegressor(),\n",
    "    param_grid=params,\n",
    "    scoring=rmsle_tuning,\n",
    "    n_jobs=12,\n",
    "    cv=ShuffleSplit(10, test_size=0.2, random_state=11).split(X_train.loc[~X_train.index.isin(outlier_ids.index)]),\n",
    "    verbose=10,\n",
    "    error_score=np.nan,\n",
    "    return_train_score=True\n",
    ")\n",
    "\n",
    "gbm.fit(\n",
    "    X_train_scaled.loc[~X_train.index.isin(outlier_ids.index)],\n",
    "    np.log1p(train_df.loc[~X_train.index.isin(outlier_ids.index), 'SalePrice'])\n",
    ")\n",
    "print(pd.DataFrame({\n",
    "    'rank': gbm.cv_results_['rank_test_score'], \n",
    "    'test': gbm.cv_results_['mean_test_score'], \n",
    "    'train': gbm.cv_results_['mean_train_score'],\n",
    "    'decay': gbm.cv_results_['mean_test_score'] / gbm.cv_results_['mean_train_score'] - 1}).sort_values('rank').iloc[:20])\n",
    "gbm.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      rank      test     train     decay\n",
      "7042     1 -0.126708 -0.095720  0.323737\n",
      "130      1 -0.126708 -0.095720  0.323737\n",
      "3586     1 -0.126708 -0.095720  0.323737\n",
      "129      4 -0.127028 -0.101673  0.249374\n",
      "3585     4 -0.127028 -0.101673  0.249374\n",
      "7041     4 -0.127028 -0.101673  0.249374\n",
      "7061     7 -0.127081 -0.092996  0.366518\n",
      "149      7 -0.127081 -0.092996  0.366518\n",
      "3605     7 -0.127081 -0.092996  0.366518\n",
      "3611    10 -0.127107 -0.096045  0.323412\n",
      "155     10 -0.127107 -0.096045  0.323412\n",
      "7067    10 -0.127107 -0.096045  0.323412\n",
      "3583    13 -0.127126 -0.098649  0.288668\n",
      "127     13 -0.127126 -0.098649  0.288668\n",
      "7039    13 -0.127126 -0.098649  0.288668\n",
      "7047    16 -0.127186 -0.105270  0.208191\n",
      "3591    16 -0.127186 -0.105270  0.208191\n",
      "135     16 -0.127186 -0.105270  0.208191\n",
      "7060    19 -0.127209 -0.095185  0.336441\n",
      "3604    19 -0.127209 -0.095185  0.336441\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GradientBoostingRegressor(alpha=0.1, max_depth=4, max_features='sqrt',\n",
       "                          max_leaf_nodes=10, min_samples_leaf=0.01,\n",
       "                          min_samples_split=0.05, n_estimators=200,\n",
       "                          n_iter_no_change=25, random_state=11, subsample=0.75,\n",
       "                          tol=0.001)"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(pd.DataFrame({\n",
    "    'rank': gbm.cv_results_['rank_test_score'], \n",
    "    'test': gbm.cv_results_['mean_test_score'], \n",
    "    'train': gbm.cv_results_['mean_train_score'],\n",
    "    'decay': gbm.cv_results_['mean_test_score'] / gbm.cv_results_['mean_train_score'] - 1}).sort_values('rank').iloc[:20])\n",
    "gbm.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_model = ada_lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaBoostRegressor(base_estimator=Lasso(alpha=0.001, max_iter=5000,\n",
       "                                       random_state=11, tol=1e-06),\n",
       "                  learning_rate=0.0005, loss='exponential', random_state=11)"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission_model.fit(X=X_train_pca.loc[~X_train.index.isin(outlier_ids.index)],\n",
    "    y=np.log1p(train_df.loc[~X_train.index.isin(outlier_ids.index), 'SalePrice']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Id      SalePrice\n",
      "0  1461  107736.350621\n",
      "1  1462  169565.171517\n",
      "2  1463  184018.570789\n",
      "3  1464  203668.790146\n",
      "4  1465  182963.720246\n"
     ]
    }
   ],
   "source": [
    "predicted_df = submission_df[['Id']].copy(deep=True)\n",
    "predicted_df['SalePrice'] = np.expm1(submission_model.predict(X_submission_pca))\n",
    "print(predicted_df.head())\n",
    "predicted_df.to_csv('2020-09-10-ada-lasso-PCA-PowerTransformer.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
